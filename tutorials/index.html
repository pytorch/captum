<!DOCTYPE html><html lang=""><head><meta charSet="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><title>Captum · Model Interpretability for PyTorch</title><meta name="viewport" content="width=device-width"/><meta name="generator" content="Docusaurus"/><meta name="description" content="Model Interpretability for PyTorch"/><meta property="og:title" content="Captum · Model Interpretability for PyTorch"/><meta property="og:type" content="website"/><meta property="og:url" content="https://captum.ai/"/><meta property="og:description" content="Model Interpretability for PyTorch"/><meta property="og:image" content="https://captum.ai/img/captum-icon.png"/><meta name="twitter:card" content="summary"/><meta name="twitter:image" content="https://captum.ai/img/captum.png"/><link rel="shortcut icon" href="/img/captum.ico"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/docsearch.js/1/docsearch.min.css"/><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css"/><script>
              (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
              (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
              m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
              })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

              ga('create', 'UA-44373548-48', 'auto');
              ga('send', 'pageview');
            </script><script type="text/javascript" src="https://buttons.github.io/buttons.js"></script><script type="text/javascript" src="/js/code_block_buttons.js"></script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.0/clipboard.min.js"></script><script src="https://unpkg.com/vanilla-back-to-top@7.1.14/dist/vanilla-back-to-top.min.js"></script><script>
        document.addEventListener('DOMContentLoaded', function() {
          addBackToTop(
            {"zIndex":100}
          )
        });
        </script><script src="/js/scrollSpy.js"></script><link rel="stylesheet" href="/css/main.css"/><script src="/js/codetabs.js"></script></head><body><div class="fixedHeaderContainer"><div class="headerWrapper wrapper"><header><a href="/"><img class="logo" src="/img/captum_logo.svg" alt="Captum"/></a><div class="navigationWrapper navigationSlider"><nav class="slidingNav"><ul class="nav-site nav-site-internal"><li class=""><a href="/docs/introduction" target="_self">Docs</a></li><li class=""><a href="/tutorials/" target="_self">Tutorials</a></li><li class=""><a href="/api/" target="_self">API Reference</a></li><li class=""><a href="https://github.com/pytorch/captum" target="_self">GitHub</a></li><li class="navSearchWrapper reactNavSearchWrapper"><input type="text" id="search_input_react" placeholder="Search" title="Search"/></li></ul></nav></div></header></div></div><div class="navPusher"><div class="docMainWrapper wrapper"><div class="container docsNavContainer" id="docsNav"><nav class="toc"><div class="toggleNav"><section class="navWrapper wrapper"><div class="navBreadcrumb wrapper"><div class="navToggle" id="navToggler"><div class="hamburger-menu"><div class="line1"></div><div class="line2"></div><div class="line3"></div></div></div><h2><i>›</i><span></span></h2><div class="tocToggler" id="tocToggler"><i class="icon-toc"></i></div></div><div class="navGroups"><div class="navGroup"><h3 class="navGroupCategoryTitle">Captum Tutorials</h3><ul class=""><li class="navListItem navListItemActive"><a class="navItem" href="/tutorials/">Overview</a></li></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle">Introduction to Captum</h3><ul class=""><li class="navListItem"><a class="navItem" href="/tutorials/Titanic_Basic_Interpret">Getting started with Captum</a></li></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle">Attribution</h3><ul class=""><li class="navListItem"><a class="navItem" href="/tutorials/IMDB_TorchText_Interpret">Interpreting text models</a></li><li class="navListItem"><a class="navItem" href="/tutorials/CIFAR_TorchVision_Interpret">Intepreting vision with CIFAR</a></li><li class="navListItem"><a class="navItem" href="/tutorials/TorchVision_Interpret">Interpreting vision with Pretrained Models</a></li><li class="navListItem"><a class="navItem" href="/tutorials/Resnet_TorchVision_Ablation">Feature ablation on images with ResNet</a></li><li class="navListItem"><a class="navItem" href="/tutorials/Multimodal_VQA_Interpret">Interpreting multimodal models</a></li><li class="navListItem"><a class="navItem" href="/tutorials/House_Prices_Regression_Interpret">Interpreting a regression model of California house prices</a></li><li class="navListItem"><a class="navItem" href="/tutorials/Segmentation_Interpret">Interpreting semantic segmentation models</a></li><li class="navListItem"><a class="navItem" href="/tutorials/Distributed_Attribution">Using Captum with torch.distributed</a></li><li class="navListItem"><a class="navItem" href="/tutorials/DLRM_Tutorial">Interpreting Deep Learning Recommender Models</a></li><li class="navListItem"><a class="navItem" href="/tutorials/Image_and_Text_Classification_LIME">Interpreting vision and text models with LIME</a></li><li class="navListItem"><a class="navItem" href="/tutorials/Llama2_LLM_Attribution">Understanding Llama2 with Captum LLM Attribution</a></li><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">Interpreting BERT</h4><ul><li class="navListItem"><a class="navItem" href="/tutorials/Bert_SQUAD_Interpret">Interpreting question answering with BERT Part 1</a></li><li class="navListItem"><a class="navItem" href="/tutorials/Bert_SQUAD_Interpret2">Interpreting question answering with BERT Part 2</a></li></ul></div></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle">Robustness</h3><ul class=""><li class="navListItem"><a class="navItem" href="/tutorials/CIFAR_Captum_Robustness">Applying robustness attacks and metrics to CIFAR model and dataset</a></li></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle">Concept</h3><ul class=""><li class="navListItem"><a class="navItem" href="/tutorials/TCAV_Image">TCAV for image classification for googlenet model</a></li><li class="navListItem"><a class="navItem" href="/tutorials/TCAV_NLP">TCAV for NLP sentiment analysis model</a></li></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle">Influential Examples</h3><ul class=""><li class="navListItem"><a class="navItem" href="/tutorials/TracInCP_Tutorial">Identifying influential examples and mis-labelled examples with TracInCP</a></li></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle">Captum Insight</h3><ul class=""><li class="navListItem"><a class="navItem" href="/tutorials/CIFAR_TorchVision_Captum_Insights">Getting started with Captum Insights</a></li><li class="navListItem"><a class="navItem" href="/tutorials/Multimodal_VQA_Captum_Insights">Using Captum Insights with multimodal models (VQA)</a></li></ul></div></div></section></div><script>
            var coll = document.getElementsByClassName('collapsible');
            var checkActiveCategory = true;
            for (var i = 0; i < coll.length; i++) {
              var links = coll[i].nextElementSibling.getElementsByTagName('*');
              if (checkActiveCategory){
                for (var j = 0; j < links.length; j++) {
                  if (links[j].classList.contains('navListItemActive')){
                    coll[i].nextElementSibling.classList.toggle('hide');
                    coll[i].childNodes[1].classList.toggle('rotate');
                    checkActiveCategory = false;
                    break;
                  }
                }
              }

              coll[i].addEventListener('click', function() {
                var arrow = this.childNodes[1];
                arrow.classList.toggle('rotate');
                var content = this.nextElementSibling;
                content.classList.toggle('hide');
              });
            }

            document.addEventListener('DOMContentLoaded', function() {
              createToggler('#navToggler', '#docsNav', 'docsSliderActive');
              createToggler('#tocToggler', 'body', 'tocActive');

              var headings = document.querySelector('.toc-headings');
              headings && headings.addEventListener('click', function(event) {
                var el = event.target;
                while(el !== headings){
                  if (el.tagName === 'A') {
                    document.body.classList.remove('tocActive');
                    break;
                  } else{
                    el = el.parentNode;
                  }
                }
              }, false);

              function createToggler(togglerSelector, targetSelector, className) {
                var toggler = document.querySelector(togglerSelector);
                var target = document.querySelector(targetSelector);

                if (!toggler) {
                  return;
                }

                toggler.onclick = function(event) {
                  event.preventDefault();

                  target.classList.toggle(className);
                };
              }
            });
        </script></nav></div><div class="container mainContainer documentContainer postContainer"><div class="wrapper"><div class="post"><header class="postHeader"><h1 class="postHeaderTitle">Captum Tutorials</h1></header><body><p>The tutorials here will help you understand and use Captum. They assume that you are familiar with PyTorch and its basic features.</p><p>If you are new to Captum, the easiest way to get started is with the <a href="Titanic_Basic_Interpret">Getting started with Captum</a> tutorial.</p><p>If you are new to PyTorch, the easiest way to get started is with the <a href="https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html#sphx-glr-beginner-blitz-tensor-tutorial-py">What is PyTorch?</a> tutorial.</p><p><h4>Getting started with Captum:</h4>In this tutorial we create and train a simple neural network on the Titanic survival dataset. We then use Integrated Gradients to analyze feature importance.  We then deep dive the network to assess layer and neuron importance using conductance.  Finally, we analyze a specific neuron to understand feature importance for that specific neuron.  Find the tutorial <a href="Titanic_Basic_Interpret">here</a>.<h3>Attribution</h3><h4>Interpreting text models:</h4>In this tutorial we use a pre-trained CNN model for sentiment analysis on an IMDB dataset. We use Captum and Integrated Gradients to interpret model predictions by show which specific words have highest attribution to the model output.  Find the tutorial <a href="IMDB_TorchText_Interpret">here </a>.<h4>Interpreting vision with CIFAR:</h4>This tutorial demonstrates how to use Captum for interpreting vision focused models. First we create and train (or use a pre-trained) a simple CNN model on the CIFAR dataset. We then interpret the output of an example with a series of overlays using Integrated Gradients and DeepLIFT. Find the tutorial <a href="CIFAR_TorchVision_Interpret">here</a>.<h4>Interpreting vision with Pretrained models:</h4>Like the CIFAR based tutorial above, this tutorial demonstrates how to use Captum for interpreting vision-focused models. This tutorial begins with a pretrained resnet18 and VGG16 model and demonstrates how to use Intergrated Gradients along with Noise Tunnel, GradientShap, Occlusion, and LRP. Find the tutorial <a href="TorchVision_Interpret">here</a>.<h4>Feature ablation on images:</h4>This tutorial demonstrates feature ablation in Captum, applied on images as an example. It leverages segmentation masks to define ablation groups over the input features. We show how this kind of analysis helps understanding which parts of the input impacts a certain target in the model. Find the tutorial <a href="Resnet_TorchVision_Ablation">here</a>.<h4>Interpreting multimodal models:</h4>To demonstrate interpreting multimodal models we have chosen to look at an open source Visual Question Answer (VQA) model. Using Captum and Integrated Gradients we interpret the output of several test questions and analyze the attribution scores of the text and visual parts of the model. Find the tutorial <a href="Multimodal_VQA_Interpret">here</a>.<h4>Understanding Llama2 with Captum LLM Attribution:</h4>This tutorial demonstrates how to easily use the LLM attribution functionality to interpret the large langague models (LLM) in text generation. It takes Llama2 as the example and shows the step-by-step improvements from the basic attribution setting to more advanced techniques. Find the tutorial <a href="Llama2_LLM_Attribution">here</a>.<h4>Interpreting question answering with BERT Part 1:</h4>This tutorial demonstrates how to use Captum to interpret a BERT model for question answering. We use a pre-trained model from Hugging Face fine-tuned on the SQUAD dataset and show how to use hooks to examine and better understand embeddings, sub-embeddings, BERT, and attention layers. Find the tutorial <a href="Bert_SQUAD_Interpret">here</a>.<h4>Interpreting question answering with BERT Part 2:</h4>In the second part of Bert tutorial we analyze attention matrices using attribution algorithms s.a. Integrated Gradients. This analysis helps us to identify strong interaction pairs between different tokens for a specific model prediction. We compare our findings with the <a href="https://arxiv.org/pdf/2004.10102.pdf">vector norms</a> and show that attribution scores are more meaningful compared to the vector norms. Find the tutorial <a href="Bert_SQUAD_Interpret2">here</a>.<h4>Interpreting a regression model of California house prices:</h4>To demonstrate interpreting regression models we have chosen to look at the California house prices dataset. Using Captum and a variety of attribution methods, we evaluate feature importance as well as internal attribution to understand the network function. Find the tutorial <a href="House_Prices_Regression_Interpret">here</a>.<h4>Interpreting a semantic segmentation model:</h4>In this tutorial, we demonstrate applying Captum to a semantic segmentation task to understand what pixels and regions contribute to the labeling of a particular class. We explore applying GradCAM as well as Feature Ablation to a pretrained Fully-Convolutional Network model with a ResNet-101 backbone. Find the tutorial <a href="Segmentation_Interpret">here</a>.<h4>Using Captum with torch.distributed:</h4>This tutorial provides examples of using Captum with the torch.distributed package and DataParallel, allowing attributions to be computed in a distributed manner across processors, machines or GPUs. Find the tutorial <a href="Distributed_Attribution">here</a>.<h4>Intepreting DLRM models with Captum:</h4>This tutorial demonstrates how we use Captum for Deep Learning Recommender Models using<a href="https://github.com/facebookresearch/dlrm">dlrm</a> model published from facebook research and integrated gradients algorithm. It showcases feature importance differences for sparse and dense features in predicting clicked and non-clicked Ads. It also analyzes the importance of feature interaction layer and neuron importances in the final fully connected layer when predicting clicked Ads. Find the tutorial <a href="DLRM_Tutorial">here</a>.<h4>Interpreting vision and text models with LIME:</h4>This tutorial demonstrates how to interpret computer vision and text classification models using Local Interpretable Model-agnostic Explanations (LIME) algorithm. For vision it uses resnet18 model to explain image classification based on super-pixels extracted by a segmentation mask. For text it uses a classification model trained on `AG_NEWS` dataset and explains model predictions based on the word tokens in the input text. Find the tutorial <a href="Image_and_Text_Classification_LIME">here</a>.<h3>Robustness</h3><h4>Applying robustness attacks and metrics to CIFAR model and dataset:</h4>This tutorial demonstrates how to apply robustness attacks such as FGSM and PGD as well as robustness metrics such as MinParamPerturbation and AttackComparator to a model trained on CIFAR dataset. Apart from that it also demonstrates how robustness techniques can be used in conjunction with attribution algorithms. Find the tutorial <a href="CIFAR_Captum_Robustness">here</a>.<h3>Concept</h3><h4>TCAV for image classification for googlenet model:</h4>This tutorial demonstrates how to apply Testing with Concept Activation Vectors (TCAV) algorithm on image classification problem. It uses googlenet model and imagenet images to showcase the effectiveness of TCAV algorithm on interpreting zebra predictions through stripes concepts. Find the tutorial <a href="TCAV_Image">here</a>.<h4>TCAV for NLP sentiment analysis model:</h4>This tutorial demonstrates how to apply TCAV algorithm for a NLP task using movie rating dataset and a CNN-based binary sentiment classification model. It showcases that `positive adjectives` concept plays a significant role in predicting positive sentiment. Find the tutorial <a href="TCAV_NLP">here</a>.<h3>Influential Examples</h3><h4>Identifying influential examples and mis-labelled examples with TracInCP:</h4>This tutorial demonstrates two use cases of the TracInCP method: providing interpretability by identifying influential training examples for a given prediction, and identifying mis-labelled examples. These two use cases are demonstrated using the CIFAR dataset and checkpoints obtained from training a simple CNN model on it (which can also be downloaded to avoid training). Find the tutorial <a href="TracInCP_Tutorial">here</a>.<h3>Captum Insight</h3><h4>Getting Started with Captum Insights:</h4>This tutorial demonstrates how to use Captum Insights for a vision model in a notebook setting.  A simple pretrained torchvision CNN model is loaded and then used on the CIFAR dataset.  Captum Insights is then loaded to visualize the interpretation of specific examples. Find the tutorial <a href="CIFAR_TorchVision_Captum_Insights">here</a>.<h4>Using Captum Insights with multimodal models (VQA):</h4>This tutorial demonstrates how to use Captum Insights for visualizing attributions of a multimodal model, particularly an open source Visual Question Answer (VQA) model. Find the tutorial <a href="Multimodal_VQA_Captum_Insights">here</a>.</p></body></div></div></div></div><footer class="nav-footer" id="footer"><section class="sitemap"><div class="footerSection"><h5>Docs</h5><a href="/docs/introduction">Introduction</a><a href="/docs/getting_started">Getting Started</a><a href="/tutorials/">Tutorials</a><a href="/api/">API Reference</a></div><div class="footerSection"><h5>Legal</h5><a href="https://opensource.facebook.com/legal/privacy/" target="_blank" rel="noreferrer noopener">Privacy</a><a href="https://opensource.facebook.com/legal/terms/" target="_blank" rel="noreferrer noopener">Terms</a></div><div class="footerSection"><h5>Social</h5><div class="social"><a class="github-button" href="https://github.com/pytorch/captum" data-count-href="https://github.com/pytorch/captum/stargazers" data-show-count="true" data-count-aria-label="# stargazers on GitHub" aria-label="Star Captum on GitHub">captum</a></div></div></section><a href="https://opensource.facebook.com/" target="_blank" rel="noreferrer noopener" class="fbOpenSource"><img src="/img/oss_logo.png" alt="Facebook Open Source" width="170" height="45"/></a><section class="copyright"> Copyright © 2024 Facebook Inc.</section><script>
            (function() {
              var BAD_BASE = '/captum/';
              if (window.location.origin !== 'https://captum.ai') {
                var pathname = window.location.pathname;
                var newPathname = pathname.slice(pathname.indexOf(BAD_BASE) === 0 ? BAD_BASE.length : 1);
                var newLocation = 'https://captum.ai/' + newPathname;
                console.log('redirecting to ' + newLocation);
                window.location.href = newLocation;
              }
            })();
          </script></footer></div><script type="text/javascript" src="https://cdn.jsdelivr.net/docsearch.js/1/docsearch.min.js"></script><script>
                document.addEventListener('keyup', function(e) {
                  if (e.target !== document.body) {
                    return;
                  }
                  // keyCode for '/' (slash)
                  if (e.keyCode === 191) {
                    const search = document.getElementById('search_input_react');
                    search && search.focus();
                  }
                });
              </script><script>
              var search = docsearch({
                
                apiKey: '207c27d819f967749142d8611de7cb19',
                indexName: 'captum',
                inputSelector: '#search_input_react'
              });
            </script></body></html>