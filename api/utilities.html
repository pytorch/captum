<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><title>Captum · Model Interpretability for PyTorch</title><meta name="viewport" content="width=device-width"/><meta name="generator" content="Docusaurus"/><meta name="description" content="Model Interpretability for PyTorch"/><meta name="docsearch:language" content="en"/><meta property="og:title" content="Captum · Model Interpretability for PyTorch"/><meta property="og:type" content="website"/><meta property="og:url" content="https://captum.ai/"/><meta property="og:description" content="Model Interpretability for PyTorch"/><meta property="og:image" content="https://captum.ai/img/captum-icon.png"/><meta name="twitter:card" content="summary"/><meta name="twitter:image" content="https://captum.ai/img/captum.png"/><link rel="shortcut icon" href="/img/captum.ico"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/docsearch.js/1/docsearch.min.css"/><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css"/><script>
              (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
              (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
              m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
              })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

              ga('create', 'UA-44373548-48', 'auto');
              ga('send', 'pageview');
            </script><link rel="stylesheet" href="/css/code_block_buttons.css"/><script type="text/javascript" src="https://buttons.github.io/buttons.js"></script><script type="text/javascript" src="/js/code_block_buttons.js"></script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.0/clipboard.min.js"></script><script type="text/javascript" src="/js/mathjax.js"></script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS_HTML"></script><script src="https://unpkg.com/vanilla-back-to-top@7.1.14/dist/vanilla-back-to-top.min.js"></script><script>
        document.addEventListener('DOMContentLoaded', function() {
          addBackToTop(
            {"zIndex":100}
          )
        });
        </script><script src="/js/scrollSpy.js"></script><link rel="stylesheet" href="/css/main.css"/><script src="/js/codetabs.js"></script></head><body><div class="fixedHeaderContainer"><div class="headerWrapper wrapper"><header><a href="/"><img class="logo" src="/img/captum_logo.svg" alt="Captum"/></a><div class="navigationWrapper navigationSlider"><nav class="slidingNav"><ul class="nav-site nav-site-internal"><li class=""><a href="/docs/introduction" target="_self">Docs</a></li><li class=""><a href="/tutorials/" target="_self">Tutorials</a></li><li class=""><a href="/api/" target="_self">API Reference</a></li><li class=""><a href="https://github.com/pytorch/captum" target="_self">GitHub</a></li><li class="navSearchWrapper reactNavSearchWrapper"><input type="text" id="search_input_react" placeholder="Search" title="Search"/></li></ul></nav></div></header></div></div><div class="navPusher"><div>
<script type="text/javascript" id="documentation_options" data-url_root="./"
  src="/js/documentation_options.js"></script>
<script type="text/javascript" src="/js/jquery.js"></script>
<script type="text/javascript" src="/js/underscore.js"></script>
<script type="text/javascript" src="/js/doctools.js"></script>
<script type="text/javascript" src="/js/language_data.js"></script>
<script type="text/javascript" src="/js/searchtools.js"></script>
<div class="sphinx"><div class="document">
<div class="documentwrapper">
<div class="bodywrapper">
<div class="body" role="main">
<div class="section" id="utilities">
<h1>Utilities<a class="headerlink" href="#utilities" title="Permalink to this headline">¶</a></h1>
<div class="section" id="visualization">
<h2>Visualization<a class="headerlink" href="#visualization" title="Permalink to this headline">¶</a></h2>
<dl class="py function">
<dt id="captum.attr.visualization.visualize_image_attr">
<code class="sig-prename descclassname">captum.attr.visualization.</code><code class="sig-name descname">visualize_image_attr</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">attr</span></em>, <em class="sig-param"><span class="n">original_image</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">method</span><span class="o">=</span><span class="default_value">'heat_map'</span></em>, <em class="sig-param"><span class="n">sign</span><span class="o">=</span><span class="default_value">'absolute_value'</span></em>, <em class="sig-param"><span class="n">plt_fig_axis</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">outlier_perc</span><span class="o">=</span><span class="default_value">2</span></em>, <em class="sig-param"><span class="n">cmap</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">alpha_overlay</span><span class="o">=</span><span class="default_value">0.5</span></em>, <em class="sig-param"><span class="n">show_colorbar</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">title</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">fig_size</span><span class="o">=</span><span class="default_value">6, 6</span></em>, <em class="sig-param"><span class="n">use_pyplot</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#captum.attr.visualization.visualize_image_attr" title="Permalink to this definition">¶</a></dt>
<dd><p>Visualizes attribution for a given image by normalizing attribution values
of the desired sign (positive, negative, absolute value, or all) and displaying
them using the desired mode in a matplotlib figure.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>attr</strong> (<em>numpy.array</em>) – Numpy array corresponding to attributions to be
visualized. Shape must be in the form (H, W, C), with
channels as last dimension. Shape must also match that of
the original image if provided.</p></li>
<li><p><strong>original_image</strong> (<em>numpy.array</em><em>, </em><em>optional</em>) – Numpy array corresponding to
original image. Shape must be in the form (H, W, C), with
channels as the last dimension. Image can be provided either
with float values in range 0-1 or int values between 0-255.
This is a necessary argument for any visualization method
which utilizes the original image.
Default: None</p></li>
<li><p><strong>method</strong> (<em>string</em><em>, </em><em>optional</em>) – <p>Chosen method for visualizing attribution.
Supported options are:</p>
<ol class="arabic simple">
<li><p><cite>heat_map</cite> - Display heat map of chosen attributions</p></li>
<li><p><cite>blended_heat_map</cite> - Overlay heat map over greyscale
version of original image. Parameter alpha_overlay
corresponds to alpha of heat map.</p></li>
<li><p><cite>original_image</cite> - Only display original image.</p></li>
<li><p><cite>masked_image</cite> - Mask image (pixel-wise multiply)
by normalized attribution values.</p></li>
<li><p><cite>alpha_scaling</cite> - Sets alpha channel of each pixel
to be equal to normalized attribution value.</p></li>
</ol>
<p>Default: <cite>heat_map</cite></p>
</p></li>
<li><p><strong>sign</strong> (<em>string</em><em>, </em><em>optional</em>) – <p>Chosen sign of attributions to visualize. Supported
options are:</p>
<ol class="arabic simple">
<li><p><cite>positive</cite> - Displays only positive pixel attributions.</p></li>
<li><p><cite>absolute_value</cite> - Displays absolute value of
attributions.</p></li>
<li><p><cite>negative</cite> - Displays only negative pixel attributions.</p></li>
<li><p><cite>all</cite> - Displays both positive and negative attribution
values. This is not supported for <cite>masked_image</cite> or
<cite>alpha_scaling</cite> modes, since signed information cannot
be represented in these modes.</p></li>
</ol>
<p>Default: <cite>absolute_value</cite></p>
</p></li>
<li><p><strong>plt_fig_axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)"><em>tuple</em></a><em>, </em><em>optional</em>) – Tuple of matplotlib.pyplot.figure and axis
on which to visualize. If None is provided, then a new figure
and axis are created.
Default: None</p></li>
<li><p><strong>outlier_perc</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em>, </em><em>optional</em>) – Top attribution values which
correspond to a total of outlier_perc percentage of the
total attribution are set to 1 and scaling is performed
using the minimum of these values. For sign=`all`, outliers a
nd scale value are computed using absolute value of
attributions.
Default: 2</p></li>
<li><p><strong>cmap</strong> (<em>string</em><em>, </em><em>optional</em>) – String corresponding to desired colormap for
heatmap visualization. This defaults to “Reds” for negative
sign, “Blues” for absolute value, “Greens” for positive sign,
and a spectrum from red to green for all. Note that this
argument is only used for visualizations displaying heatmaps.
Default: None</p></li>
<li><p><strong>alpha_overlay</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a><em>, </em><em>optional</em>) – Alpha to set for heatmap when using
<cite>blended_heat_map</cite> visualization mode, which overlays the
heat map over the greyscaled original image.
Default: 0.5</p></li>
<li><p><strong>show_colorbar</strong> (<em>boolean</em><em>, </em><em>optional</em>) – Displays colorbar for heatmap below
the visualization. If given method does not use a heatmap,
then a colormap axis is created and hidden. This is
necessary for appropriate alignment when visualizing
multiple plots, some with colorbars and some without.
Default: False</p></li>
<li><p><strong>title</strong> (<em>string</em><em>, </em><em>optional</em>) – Title string for plot. If None, no title is
set.
Default: None</p></li>
<li><p><strong>fig_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)"><em>tuple</em></a><em>, </em><em>optional</em>) – Size of figure created.
Default: (6,6)</p></li>
<li><p><strong>use_pyplot</strong> (<em>boolean</em><em>, </em><em>optional</em>) – If true, uses pyplot to create and show
figure and displays the figure after creating. If False,
uses Matplotlib object oriented API and simply returns a
figure object without showing.
Default: True.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><dl class="simple">
<dt><strong>figure</strong> (<em>matplotlib.pyplot.figure</em>):</dt><dd><p>Figure object on which visualization
is created. If plt_fig_axis argument is given, this is the
same figure provided.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>axis</strong> (<em>matplotlib.pyplot.axis</em>):</dt><dd><p>Axis object on which visualization
is created. If plt_fig_axis argument is given, this is the
same axis provided.</p>
</dd>
</dl>
</li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>2-element tuple of <strong>figure</strong>, <strong>axis</strong></p>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># ImageClassifier takes a single input tensor of images Nx3x32x32,</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># and returns an Nx10 tensor of class probabilities.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">ImageClassifier</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ig</span> <span class="o">=</span> <span class="n">IntegratedGradients</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Computes integrated gradients for class 3 for a given image .</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attribution</span><span class="p">,</span> <span class="n">delta</span> <span class="o">=</span> <span class="n">ig</span><span class="o">.</span><span class="n">attribute</span><span class="p">(</span><span class="n">orig_image</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Displays blended heat map visualization of computed attributions.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">_</span> <span class="o">=</span> <span class="n">visualize_image_attr</span><span class="p">(</span><span class="n">attribution</span><span class="p">,</span> <span class="n">orig_image</span><span class="p">,</span> <span class="s2">"blended_heat_map"</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>
<dl class="py function">
<dt id="captum.attr.visualization.visualize_image_attr_multiple">
<code class="sig-prename descclassname">captum.attr.visualization.</code><code class="sig-name descname">visualize_image_attr_multiple</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">attr</span></em>, <em class="sig-param"><span class="n">original_image</span></em>, <em class="sig-param"><span class="n">methods</span></em>, <em class="sig-param"><span class="n">signs</span></em>, <em class="sig-param"><span class="n">titles</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">fig_size</span><span class="o">=</span><span class="default_value">8, 6</span></em>, <em class="sig-param"><span class="n">use_pyplot</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#captum.attr.visualization.visualize_image_attr_multiple" title="Permalink to this definition">¶</a></dt>
<dd><p>Visualizes attribution using multiple visualization methods displayed
in a 1 x k grid, where k is the number of desired visualizations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>attr</strong> (<em>numpy.array</em>) – Numpy array corresponding to attributions to be
visualized. Shape must be in the form (H, W, C), with
channels as last dimension. Shape must also match that of
the original image if provided.</p></li>
<li><p><strong>original_image</strong> (<em>numpy.array</em><em>, </em><em>optional</em>) – Numpy array corresponding to
original image. Shape must be in the form (H, W, C), with
channels as the last dimension. Image can be provided either
with values in range 0-1 or 0-255. This is a necessary
argument for any visualization method which utilizes
the original image.</p></li>
<li><p><strong>methods</strong> (<em>list of strings</em>) – List of strings of length k, defining method
for each visualization. Each method must be a valid
string argument for method to visualize_image_attr.</p></li>
<li><p><strong>signs</strong> (<em>list of strings</em>) – List of strings of length k, defining signs for
each visualization. Each sign must be a valid
string argument for sign to visualize_image_attr.</p></li>
<li><p><strong>titles</strong> (<em>list of strings</em><em>, </em><em>optional</em>) – List of strings of length k, providing
a title string for each plot. If None is provided, no titles
are added to subplots.
Default: None</p></li>
<li><p><strong>fig_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)"><em>tuple</em></a><em>, </em><em>optional</em>) – Size of figure created.
Default: (8, 6)</p></li>
<li><p><strong>use_pyplot</strong> (<em>boolean</em><em>, </em><em>optional</em>) – If true, uses pyplot to create and show
figure and displays the figure after creating. If False,
uses Matplotlib object oriented API and simply returns a
figure object without showing.
Default: True.</p></li>
<li><p><strong>**kwargs</strong> (<em>Any</em><em>, </em><em>optional</em>) – Any additional arguments which will be passed
to every individual visualization. Such arguments include
<cite>show_colorbar</cite>, <cite>alpha_overlay</cite>, <cite>cmap</cite>, etc.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><dl class="simple">
<dt><strong>figure</strong> (<em>matplotlib.pyplot.figure</em>):</dt><dd><p>Figure object on which visualization
is created. If plt_fig_axis argument is given, this is the
same figure provided.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>axis</strong> (<em>matplotlib.pyplot.axis</em>):</dt><dd><p>Axis object on which visualization
is created. If plt_fig_axis argument is given, this is the
same axis provided.</p>
</dd>
</dl>
</li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>2-element tuple of <strong>figure</strong>, <strong>axis</strong></p>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># ImageClassifier takes a single input tensor of images Nx3x32x32,</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># and returns an Nx10 tensor of class probabilities.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">ImageClassifier</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ig</span> <span class="o">=</span> <span class="n">IntegratedGradients</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Computes integrated gradients for class 3 for a given image .</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attribution</span><span class="p">,</span> <span class="n">delta</span> <span class="o">=</span> <span class="n">ig</span><span class="o">.</span><span class="n">attribute</span><span class="p">(</span><span class="n">orig_image</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Displays original image and heat map visualization of</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># computed attributions side by side.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">_</span> <span class="o">=</span> <span class="n">visualize_mutliple_image_attr</span><span class="p">(</span><span class="n">attribution</span><span class="p">,</span> <span class="n">orig_image</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                    <span class="p">[</span><span class="s2">"original_image"</span><span class="p">,</span> <span class="s2">"heat_map"</span><span class="p">],</span> <span class="p">[</span><span class="s2">"all"</span><span class="p">,</span> <span class="s2">"positive"</span><span class="p">])</span>
</pre></div>
</div>
</dd></dl>
</div>
<div class="section" id="interpretable-embeddings">
<h2>Interpretable Embeddings<a class="headerlink" href="#interpretable-embeddings" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="captum.attr.InterpretableEmbeddingBase">
<em class="property">class </em><code class="sig-prename descclassname">captum.attr.</code><code class="sig-name descname">InterpretableEmbeddingBase</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">embedding</span></em>, <em class="sig-param"><span class="n">full_name</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/captum/attr/_models/base.html#InterpretableEmbeddingBase"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#captum.attr.InterpretableEmbeddingBase" title="Permalink to this definition">¶</a></dt>
<dd><p>Since some embedding vectors, e.g. word are created and assigned in
the embedding layers of Pytorch models we need a way to access
those layers, generate the embeddings and subtract the baseline.
To do so, we separate embedding layers from the model, compute the
embeddings separately and do all operations needed outside of the model.
The original embedding layer is being replaced by
<cite>InterpretableEmbeddingBase</cite> layer which passes already
precomputed embedding vectors to the layers below.</p>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="py method">
<dt id="captum.attr.InterpretableEmbeddingBase.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">inputs</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/captum/attr/_models/base.html#InterpretableEmbeddingBase.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#captum.attr.InterpretableEmbeddingBase.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>The forward function of a wrapper embedding layer that takes and returns
embedding layer. It allows embeddings to be created outside of the model
and passes them seamlessly to the preceding layers of the model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>*inputs</strong> (<em>Any</em><em>, </em><em>optional</em>) – A sequence of inputs arguments that the
forward function takes. Since forward functions can take any
type and number of arguments, this will ensure that we can
execute the forward pass using interpretable embedding layer.
Note that if inputs are specified, it is assumed that the first
argument is the embedding tensor generated using the
<cite>self.embedding</cite> layer using all input arguments provided in
<cite>inputs</cite> and <cite>kwargs</cite>.</p></li>
<li><p><strong>**kwargs</strong> (<em>Any</em><em>, </em><em>optional</em>) – Similar to <cite>inputs</cite> we want to make sure
that our forward pass supports arbitrary number and type of
key-value arguments. If <cite>inputs</cite> is not provided, <cite>kwargs</cite> must
be provided and the first argument corresponds to the embedding
tensor generated using the <cite>self.embedding</cite>. Note that we make
here an assumption here that <cite>kwargs</cite> is an ordered dict which
is new in python 3.6 and is not guaranteed that it will
consistently remain that way in the newer versions. In case
current implementation doesn’t work for special use cases,
it is encouraged to override <cite>InterpretableEmbeddingBase</cite> and
address those specifics in descendant classes.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Returns a tensor which is the same as first argument passed
to the forward function.
It passes pre-computed embedding tensors to lower layers
without any modifications.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>embedding_tensor (Tensor)</p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt id="captum.attr.InterpretableEmbeddingBase.indices_to_embeddings">
<code class="sig-name descname">indices_to_embeddings</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">input</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/captum/attr/_models/base.html#InterpretableEmbeddingBase.indices_to_embeddings"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#captum.attr.InterpretableEmbeddingBase.indices_to_embeddings" title="Permalink to this definition">¶</a></dt>
<dd><p>Maps indices to corresponding embedding vectors. E.g. word embeddings</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>*input</strong> (<em>Any</em><em>, </em><em>Optional</em>) – This can be a tensor(s) of input indices or any
other variable necessary to comput the embeddings. A typical
example of input indices are word or token indices.</p></li>
<li><p><strong>**kwargs</strong> (<em>Any</em><em>, </em><em>optional</em>) – Similar to <cite>input</cite> this can be any sequence
of key-value arguments necessary to compute final embedding
tensor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A tensor of word embeddings corresponding to the
indices specified in the input</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tensor</p>
</dd>
</dl>
</dd></dl>
</dd></dl>
<dl class="py function">
<dt id="captum.attr.configure_interpretable_embedding_layer">
<code class="sig-prename descclassname">captum.attr.</code><code class="sig-name descname">configure_interpretable_embedding_layer</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">model</span></em>, <em class="sig-param"><span class="n">embedding_layer_name</span><span class="o">=</span><span class="default_value">'embedding'</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/captum/attr/_models/base.html#configure_interpretable_embedding_layer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#captum.attr.configure_interpretable_embedding_layer" title="Permalink to this definition">¶</a></dt>
<dd><p>This method wraps model’s embedding layer with an interpretable embedding
layer that allows us to access the embeddings through their indices.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>torch.nn.Model</em>) – An instance of PyTorch model that contains embeddings.</p></li>
<li><p><strong>embedding_layer_name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a><em>, </em><em>optional</em>) – The name of the embedding layer
in the <cite>model</cite> that we would like to make interpretable.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>An instance of <cite>InterpretableEmbeddingBase</cite></dt><dd><p>embedding layer that wraps model’s embedding layer that is being
accessed through <cite>embedding_layer_name</cite>.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>interpretable_emb (tensor)</p>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Let's assume that we have a DocumentClassifier model that</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># has a word embedding layer named 'embedding'.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># To make that layer interpretable we need to execute the</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># following command:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">DocumentClassifier</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">interpretable_emb</span> <span class="o">=</span> <span class="n">configure_interpretable_embedding_layer</span><span class="p">(</span><span class="n">net</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>   <span class="s1">'embedding'</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># then we can use interpretable embedding to convert our</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># word indices into embeddings.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Let's assume that we have the following word indices</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># we can access word embeddings for those indices with the command</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># line stated below.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_emb</span> <span class="o">=</span> <span class="n">interpretable_emb</span><span class="o">.</span><span class="n">indices_to_embeddings</span><span class="p">(</span><span class="n">input_indices</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Let's assume that we want to apply integrated gradients to</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># our model and that target attribution class is 3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ig</span> <span class="o">=</span> <span class="n">IntegratedGradients</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attribution</span> <span class="o">=</span> <span class="n">ig</span><span class="o">.</span><span class="n">attribute</span><span class="p">(</span><span class="n">input_emb</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># after we finish the interpretation we need to remove</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># interpretable embedding layer with the following command:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">remove_interpretable_embedding_layer</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">interpretable_emb</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>
<dl class="py function">
<dt id="captum.attr.remove_interpretable_embedding_layer">
<code class="sig-prename descclassname">captum.attr.</code><code class="sig-name descname">remove_interpretable_embedding_layer</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">model</span></em>, <em class="sig-param"><span class="n">interpretable_emb</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/captum/attr/_models/base.html#remove_interpretable_embedding_layer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#captum.attr.remove_interpretable_embedding_layer" title="Permalink to this definition">¶</a></dt>
<dd><p>Removes interpretable embedding layer and sets back original
embedding layer in the model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch vmaster (1.7.0a0+0bc39c0 ))"><em>torch.nn.Module</em></a>) – An instance of PyTorch model that contains embeddings</p></li>
<li><p><strong>interpretable_emb</strong> (<em>tensor</em>) – An instance of <cite>InterpretableEmbeddingBase</cite>
that was originally created in
<cite>configure_interpretable_embedding_layer</cite> function and has
to be removed after interpretation is finished.</p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Let's assume that we have a DocumentClassifier model that</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># has a word embedding layer named 'embedding'.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># To make that layer interpretable we need to execute the</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># following command:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">DocumentClassifier</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">interpretable_emb</span> <span class="o">=</span> <span class="n">configure_interpretable_embedding_layer</span><span class="p">(</span><span class="n">net</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>   <span class="s1">'embedding'</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># then we can use interpretable embedding to convert our</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># word indices into embeddings.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Let's assume that we have the following word indices</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># we can access word embeddings for those indices with the command</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># line stated below.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_emb</span> <span class="o">=</span> <span class="n">interpretable_emb</span><span class="o">.</span><span class="n">indices_to_embeddings</span><span class="p">(</span><span class="n">input_indices</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Let's assume that we want to apply integrated gradients to</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># our model and that target attribution class is 3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ig</span> <span class="o">=</span> <span class="n">IntegratedGradients</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attribution</span> <span class="o">=</span> <span class="n">ig</span><span class="o">.</span><span class="n">attribute</span><span class="p">(</span><span class="n">input_emb</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># after we finish the interpretation we need to remove</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># interpretable embedding layer with the following command:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">remove_interpretable_embedding_layer</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">interpretable_emb</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>
</div>
<div class="section" id="token-reference-base">
<h2>Token Reference Base<a class="headerlink" href="#token-reference-base" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="captum.attr.TokenReferenceBase">
<em class="property">class </em><code class="sig-prename descclassname">captum.attr.</code><code class="sig-name descname">TokenReferenceBase</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">reference_token_idx</span><span class="o">=</span><span class="default_value">0</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/captum/attr/_models/base.html#TokenReferenceBase"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#captum.attr.TokenReferenceBase" title="Permalink to this definition">¶</a></dt>
<dd><p>A base class for creating reference (aka baseline) tensor for a sequence of
tokens. A typical example of such token is <cite>PAD</cite>. Users need to provide the
index of the reference token in the vocabulary as an argument to
<cite>TokenReferenceBase</cite> class.</p>
<dl class="py method">
<dt id="captum.attr.TokenReferenceBase.generate_reference">
<code class="sig-name descname">generate_reference</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">sequence_length</span></em>, <em class="sig-param"><span class="n">device</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/captum/attr/_models/base.html#TokenReferenceBase.generate_reference"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#captum.attr.TokenReferenceBase.generate_reference" title="Permalink to this definition">¶</a></dt>
<dd><p>Generated reference tensor of given <cite>sequence_length</cite> using
<cite>reference_token_idx</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sequence_length</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – The length of the reference sequence</p></li>
<li><p><strong>device</strong> (<em>torch.device</em>) – The device on which the reference tensor will
be created.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>A sequence of reference token with shape:</dt><dd><p>[sequence_length]</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tensor</p>
</dd>
</dl>
</dd></dl>
</dd></dl>
</div>
</div>
</div>
</div>
</div>
<div aria-label="main navigation" class="sphinxsidebar" role="navigation">
<div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="index.html">Captum</a></h1>
<h3>Navigation</h3>
<p class="caption"><span class="caption-text">API Reference</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="attribution.html">Attribution</a></li>
<li class="toctree-l1"><a class="reference internal" href="noise_tunnel.html">NoiseTunnel</a></li>
<li class="toctree-l1"><a class="reference internal" href="layer.html">Layer Attribution</a></li>
<li class="toctree-l1"><a class="reference internal" href="neuron.html">Neuron Attribution</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Utilities</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#visualization">Visualization</a></li>
<li class="toctree-l2"><a class="reference internal" href="#interpretable-embeddings">Interpretable Embeddings</a></li>
<li class="toctree-l2"><a class="reference internal" href="#token-reference-base">Token Reference Base</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="base_classes.html">Base Classes</a></li>
</ul>
<p class="caption"><span class="caption-text">Insights API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="insights.html">Insights</a></li>
<li class="toctree-l1"><a class="reference internal" href="insights.html#features">Features</a></li>
</ul>
<div class="relations">
<h3>Related Topics</h3>
<ul>
<li><a href="index.html">Documentation overview</a><ul>
<li>Previous: <a href="neuron.html" title="previous chapter">Neuron Attribution</a></li>
<li>Next: <a href="base_classes.html" title="next chapter">Base Classes</a></li>
</ul></li>
</ul>
</div>
<div id="searchbox" role="search" style="display: none">
<h3 id="searchlabel">Quick search</h3>
<div class="searchformwrapper">
<form action="search.html" class="search" method="get">
<input aria-labelledby="searchlabel" name="q" type="text"/>
<input type="submit" value="Go"/>
</form>
</div>
</div>
<script>$('#searchbox').show(0);</script>
</div>
</div>
<div class="clearer"></div>
</div></div></div><footer class="nav-footer" id="footer"><section class="sitemap"><div class="footerSection"><h5>Docs</h5><a href="/docs/introduction">Introduction</a><a href="/docs/getting_started">Getting Started</a><a href="/tutorials/">Tutorials</a><a href="/api/">API Reference</a></div><div class="footerSection"><h5>Social</h5><div class="social"><a class="github-button" href="https://github.com/pytorch/captum" data-count-href="https://github.com/pytorch/captum/stargazers" data-show-count="true" data-count-aria-label="# stargazers on GitHub" aria-label="Star Captum on GitHub">captum</a></div></div></section><a href="https://opensource.facebook.com/" target="_blank" rel="noreferrer noopener" class="fbOpenSource"><img src="/img/oss_logo.png" alt="Facebook Open Source" width="170" height="45"/></a><section class="copyright"> Copyright © 2020 Facebook Inc.</section><script>
            (function() {
              var BAD_BASE = '/captum/';
              if (window.location.origin !== 'https://captum.ai') {
                var pathname = window.location.pathname;
                var newPathname = pathname.slice(pathname.indexOf(BAD_BASE) === 0 ? BAD_BASE.length : 1);
                var newLocation = 'https://captum.ai/' + newPathname;
                console.log('redirecting to ' + newLocation);
                window.location.href = newLocation;
              }
            })();
          </script></footer></div><script type="text/javascript" src="https://cdn.jsdelivr.net/docsearch.js/1/docsearch.min.js"></script><script>
                document.addEventListener('keyup', function(e) {
                  if (e.target !== document.body) {
                    return;
                  }
                  // keyCode for '/' (slash)
                  if (e.keyCode === 191) {
                    const search = document.getElementById('search_input_react');
                    search && search.focus();
                  }
                });
              </script><script>
              var search = docsearch({
                
                apiKey: '207c27d819f967749142d8611de7cb19',
                indexName: 'captum',
                inputSelector: '#search_input_react'
              });
            </script></body></html>