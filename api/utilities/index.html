<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><title>Captum · Model Interpretability for PyTorch</title><meta name="viewport" content="width=device-width"/><meta name="generator" content="Docusaurus"/><meta name="description" content="Model Interpretability for PyTorch"/><meta name="docsearch:language" content="en"/><meta property="og:title" content="Captum · Model Interpretability for PyTorch"/><meta property="og:type" content="website"/><meta property="og:url" content="https://captum.ai/"/><meta property="og:description" content="Model Interpretability for PyTorch"/><meta property="og:image" content="https://captum.ai/img/captum-icon.png"/><meta name="twitter:card" content="summary"/><meta name="twitter:image" content="https://captum.ai/img/captum.png"/><link rel="shortcut icon" href="/img/captum.ico"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/docsearch.js/1/docsearch.min.css"/><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css"/><script>
              (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
              (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
              m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
              })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

              ga('create', 'UA-44373548-48', 'auto');
              ga('send', 'pageview');
            </script><script type="text/javascript" src="https://buttons.github.io/buttons.js"></script><script type="text/javascript" src="/js/code_block_buttons.js"></script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.0/clipboard.min.js"></script><script src="https://unpkg.com/vanilla-back-to-top@7.1.14/dist/vanilla-back-to-top.min.js"></script><script>
        document.addEventListener('DOMContentLoaded', function() {
          addBackToTop(
            {"zIndex":100}
          )
        });
        </script><script src="/js/scrollSpy.js"></script><link rel="stylesheet" href="/css/main.css"/><script src="/js/codetabs.js"></script></head><body><div class="fixedHeaderContainer"><div class="headerWrapper wrapper"><header><a href="/"><img class="logo" src="/img/captum_logo.svg" alt="Captum"/></a><div class="navigationWrapper navigationSlider"><nav class="slidingNav"><ul class="nav-site nav-site-internal"><li class=""><a href="/docs/introduction" target="_self">Docs</a></li><li class=""><a href="/tutorials/" target="_self">Tutorials</a></li><li class=""><a href="/api/" target="_self">API Reference</a></li><li class=""><a href="https://github.com/pytorch/captum" target="_self">GitHub</a></li><li class="navSearchWrapper reactNavSearchWrapper"><input type="text" id="search_input_react" placeholder="Search" title="Search"/></li></ul></nav></div></header></div></div><div class="navPusher"><div>
<script type="text/javascript" id="documentation_options" data-url_root="./"
src="/_sphinx/documentation_options.js"></script>
<script type="text/javascript" src="/_sphinx/jquery.js"></script>
<script type="text/javascript" src="/_sphinx/underscore.js"></script>
<script type="text/javascript" src="/_sphinx/doctools.js"></script>
<script type="text/javascript" src="/_sphinx/language_data.js"></script>
<script type="text/javascript" src="/_sphinx/searchtools.js"></script>

<script src="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/contrib/auto-render.min.js"></script>
<script src="/_sphinx/katex_autorenderer.js"></script>
<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.css" />
<div class="sphinx wrapper"><div class="document">
<div class="documentwrapper">
<div class="bodywrapper">
<div class="body" role="main">
<section id="utilities">
<h1>Utilities<a class="headerlink" href="#utilities" title="Link to this heading">¶</a></h1>
<section id="interpretable-input">
<h2>Interpretable Input<a class="headerlink" href="#interpretable-input" title="Link to this heading">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="captum.attr.InterpretableInput">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">captum.attr.</span></span><span class="sig-name descname"><span class="pre">InterpretableInput</span></span><a class="reference internal" href="_modules/captum/attr/_utils/interpretable_input.html#InterpretableInput"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#captum.attr.InterpretableInput" title="Link to this definition">¶</a></dt>
<dd><p>InterpretableInput is an adapter for different kinds of model inputs to
work in Captum’s attribution methods. Generally, attribution methods of Captum
assume the inputs are numerical PyTorch tensors whose 1st dimension must be batch
size and each index in the rest of dimensions is an interpretable feature. But this
is not always true in practice. First, the model may take inputs of formats other
than tensor that also require attributions. For example, a model with encapsulated
tokenizer can directly take string as input. Second, what is considered as
an interpretable feature always depends on the actual application and the user’s
desire. For example, the interpretable feature of an image tensor can either be
each pixel or some segments. For text, users may see the entire string as one
interpretable feature or view each word as one interpretable feature. This class
provides a place to define what is the actual model input and the corresponding
interpretable format for attribution, and the transformation between them.
It serves as a common interface to be used inthe attribution methods to make
Captum understand how to perturb various inputs.</p>
<p>The concept Interpretable Input mainly comes from the following two papers:</p>
<p><a class="reference external" href="https://arxiv.org/abs/1602.04938">“Why Should I Trust You?”: Explaining the Predictions of Any Classifier</a></p>
<p><a class="reference external" href="https://arxiv.org/abs/1705.07874">A Unified Approach to Interpreting Model Predictions</a></p>
<p>which is also referred to as interpretable representation or simplified
input. It can be represented as a mapping function:</p>
<div class="math">
\[x = h_x(x')

\]</div>
<p>where <span class="math">\(x\)</span> is the model input, which can be anything that the model consumes;
<span class="math">\(x'\)</span> is the interpretable input used in the attribution algorithms
(it must be a PyTorch tensor in Captum), which is often
binary indicating the “presence” or “absence”; <span class="math">\(h_x\)</span> is the
transformer. It is supposed to work with perturbation-based attribution methods,
but if <span class="math">\(h_x\)</span> is differentiable, it may also be used
in gradient-based methods.</p>
<p>InterpretableInput is the abstract class defining the interface. Captum provides
the child implementations for some common input formats,
like text and sparse features. Users can inherit this
class to create other types of customized input.</p>
<p>(We expect to support InterpretableInput in all attribution methods, but it
is only allowed in certain attribution classes like LLMAttribution for now.)</p>
<dl class="py method">
<dt class="sig sig-object py" id="captum.attr.InterpretableInput.format_attr">
<span class="sig-name descname"><span class="pre">format_attr</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">itp_attr</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/captum/attr/_utils/interpretable_input.html#InterpretableInput.format_attr"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#captum.attr.InterpretableInput.format_attr" title="Link to this definition">¶</a></dt>
<dd><p>Format the attribution of the interpretable feature if needed.
The way of formatting depends on the specific interpretable input type.
A common use is if the interpretable features are the mask groups of the raw
input elements, the attribution of the interpretable features can be scattered
back to the model input shape.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>itp_attr</strong> (<a class="reference external" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.5)"><em>Tensor</em></a>) – attributions of the interpretable features</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>formatted attribution</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>attr (Tensor)</p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="captum.attr.InterpretableInput.to_model_input">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">to_model_input</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">perturbed_tensor</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/captum/attr/_utils/interpretable_input.html#InterpretableInput.to_model_input"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#captum.attr.InterpretableInput.to_model_input" title="Link to this definition">¶</a></dt>
<dd><p>Get the (perturbed) input in the format required by the model
based on the given (perturbed) interpretable representation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>perturbed_tensor</strong> (<a class="reference external" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.5)"><em>Tensor</em></a><em>, </em><em>optional</em>) – tensor of the interpretable
representation of this input. If it is None, assume the
interpretable representation is pristine and return the
original model input
Default: None.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>model input passed to the forward function</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>model_input (Any)</p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="captum.attr.InterpretableInput.to_tensor">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">to_tensor</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/captum/attr/_utils/interpretable_input.html#InterpretableInput.to_tensor"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#captum.attr.InterpretableInput.to_tensor" title="Link to this definition">¶</a></dt>
<dd><p>Return the interpretable representation of this input as a tensor</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>interpretable tensor</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>itp_tensor (Tensor)</p>
</dd>
</dl>
</dd></dl>
</dd></dl>
<dl class="py class">
<dt class="sig sig-object py" id="captum.attr.TextTemplateInput">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">captum.attr.</span></span><span class="sig-name descname"><span class="pre">TextTemplateInput</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">template</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">values</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">baselines</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/captum/attr/_utils/interpretable_input.html#TextTemplateInput"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#captum.attr.TextTemplateInput" title="Link to this definition">¶</a></dt>
<dd><p>TextTemplateInput is an implementation of InterpretableInput for text inputs, whose
interpretable features are certain segments (e.g., words, phrases) of the text.
It takes a template string (or function) to define the feature segmentats
of the input text. Its input format to the model will be the completed text,
while its interpretable representation will be a binary tensor of the number of
the segment features whose values indicates if the feature is
“presence” or “absence”.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>template</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Callable" title="(in Python v3.13)"><em>Callable</em></a>) – template string or function that takes
the text segments and format them into the text input for the model</p></li>
<li><p><strong>values</strong> (<em>List</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>] or </em><em>Dict</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>]</em>) – the values of the segments. it is
the input to the template.</p></li>
<li><p><strong>baselines</strong> (<em>List</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>] or </em><em>Dict</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>] or </em><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Callable" title="(in Python v3.13)"><em>Callable</em></a><em> or </em><em>None</em><em>, </em><em>optional</em>) – the
baseline values for the segment features. If it is None, emptry string
will be used as the baseline.
Default: None</p></li>
<li><p><strong>mask</strong> (<em>List</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>] or </em><em>Dict</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>] or </em><em>None</em><em>, </em><em>optional</em>) – the mask to group the
segment features. It must be in the same format as the values
and assign each segment a mask index. Segments with the same
index will be seen as a single interpretable feature, which means
they must be perturbed together and end with same attributions.
Default: None</p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">text_inp</span> <span class="o">=</span> <span class="n">TextTemplateInput</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">template</span><span class="o">=</span><span class="s2">"</span><span class="si">{}</span><span class="s2"> feels </span><span class="si">{}</span><span class="s2"> right now"</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">values</span><span class="o">=</span><span class="p">[</span><span class="s2">"He"</span><span class="p">,</span> <span class="s2">"depressed"</span><span class="p">],</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">baselines</span><span class="o">=</span><span class="p">[</span><span class="s2">"It"</span><span class="p">,</span> <span class="s2">"neutral"</span><span class="p">],</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">text_inp</span><span class="o">.</span><span class="n">to_tensor</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># torch.tensor([[1, 1]])</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">text_inp</span><span class="o">.</span><span class="n">to_model_input</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># "It feels depressed right now"</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="captum.attr.TextTemplateInput.format_attr">
<span class="sig-name descname"><span class="pre">format_attr</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">itp_attr</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/captum/attr/_utils/interpretable_input.html#TextTemplateInput.format_attr"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#captum.attr.TextTemplateInput.format_attr" title="Link to this definition">¶</a></dt>
<dd><p>Format the attribution of the interpretable feature if needed.
The way of formatting depends on the specific interpretable input type.
A common use is if the interpretable features are the mask groups of the raw
input elements, the attribution of the interpretable features can be scattered
back to the model input shape.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>itp_attr</strong> (<a class="reference external" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.5)"><em>Tensor</em></a>) – attributions of the interpretable features</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>formatted attribution</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>attr (Tensor)</p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="captum.attr.TextTemplateInput.to_model_input">
<span class="sig-name descname"><span class="pre">to_model_input</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">perturbed_tensor</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/captum/attr/_utils/interpretable_input.html#TextTemplateInput.to_model_input"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#captum.attr.TextTemplateInput.to_model_input" title="Link to this definition">¶</a></dt>
<dd><p>Get the (perturbed) input in the format required by the model
based on the given (perturbed) interpretable representation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>perturbed_tensor</strong> (<a class="reference external" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.5)"><em>Tensor</em></a><em>, </em><em>optional</em>) – tensor of the interpretable
representation of this input. If it is None, assume the
interpretable representation is pristine and return the
original model input
Default: None.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>model input passed to the forward function</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>model_input (Any)</p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="captum.attr.TextTemplateInput.to_tensor">
<span class="sig-name descname"><span class="pre">to_tensor</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/captum/attr/_utils/interpretable_input.html#TextTemplateInput.to_tensor"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#captum.attr.TextTemplateInput.to_tensor" title="Link to this definition">¶</a></dt>
<dd><p>Return the interpretable representation of this input as a tensor</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>interpretable tensor</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>itp_tensor (Tensor)</p>
</dd>
</dl>
</dd></dl>
</dd></dl>
<dl class="py class">
<dt class="sig sig-object py" id="captum.attr.TextTokenInput">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">captum.attr.</span></span><span class="sig-name descname"><span class="pre">TextTokenInput</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tokenizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">baselines</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">skip_tokens</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/captum/attr/_utils/interpretable_input.html#TextTokenInput"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#captum.attr.TextTokenInput" title="Link to this definition">¶</a></dt>
<dd><p>TextTokenInput is an implementation of InterpretableInput for text inputs, whose
interpretable features are the tokens of the text with respect to a given tokenizer.
It is initiated with the string form of the input text and the corresponding
tokenizer. Its input format to the model will be the tokenized id tensor,
while its interpretable representation will be a binary tensor of the tokens
whose values indicates if the token is “presence” or “absence”.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – text string for the model</p></li>
<li><p><strong>tokenizer</strong> (<em>Tokenizer</em>) – tokenizer of the language model</p></li>
<li><p><strong>baselines</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – the
baseline value for the tokens. It can be a string of the baseline token
or an integer of the baseline token id. Common choices include unknown
token or padding token. The default value is 0, which
is commonly used for unknown token.
Default: 0</p></li>
<li><p><strong>skip_tokens</strong> (<em>List</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>] or </em><em>List</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>]</em><em>, </em><em>optional</em>) – the tokens to skip in the
the input’s interpretable representation. Use this argument to define
uninterested tokens, commonly like special tokens, e.g., sos, and unk.
It can be a list of strings of the tokens or a list of integers of the
token ids.
Default: None</p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">text_inp</span> <span class="o">=</span> <span class="n">TextTokenInput</span><span class="p">(</span><span class="s2">"This is a test."</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">text_inp</span><span class="o">.</span><span class="n">to_tensor</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># the shape dependens on the tokenizer</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># assuming it is broken into ["&lt;s&gt;", "This", "is", "a", "test", "."],</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># torch.tensor([[1, 6]])</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">text_inp</span><span class="o">.</span><span class="n">to_model_input</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># torch.tensor([[1, 6]])</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="captum.attr.TextTokenInput.format_attr">
<span class="sig-name descname"><span class="pre">format_attr</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">itp_attr</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/captum/attr/_utils/interpretable_input.html#TextTokenInput.format_attr"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#captum.attr.TextTokenInput.format_attr" title="Link to this definition">¶</a></dt>
<dd><p>Format the attribution of the interpretable feature if needed.
The way of formatting depends on the specific interpretable input type.
A common use is if the interpretable features are the mask groups of the raw
input elements, the attribution of the interpretable features can be scattered
back to the model input shape.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>itp_attr</strong> (<a class="reference external" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.5)"><em>Tensor</em></a>) – attributions of the interpretable features</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>formatted attribution</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>attr (Tensor)</p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="captum.attr.TextTokenInput.to_model_input">
<span class="sig-name descname"><span class="pre">to_model_input</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">perturbed_tensor</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/captum/attr/_utils/interpretable_input.html#TextTokenInput.to_model_input"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#captum.attr.TextTokenInput.to_model_input" title="Link to this definition">¶</a></dt>
<dd><p>Get the (perturbed) input in the format required by the model
based on the given (perturbed) interpretable representation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>perturbed_tensor</strong> (<a class="reference external" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.5)"><em>Tensor</em></a><em>, </em><em>optional</em>) – tensor of the interpretable
representation of this input. If it is None, assume the
interpretable representation is pristine and return the
original model input
Default: None.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>model input passed to the forward function</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>model_input (Any)</p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="captum.attr.TextTokenInput.to_tensor">
<span class="sig-name descname"><span class="pre">to_tensor</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/captum/attr/_utils/interpretable_input.html#TextTokenInput.to_tensor"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#captum.attr.TextTokenInput.to_tensor" title="Link to this definition">¶</a></dt>
<dd><p>Return the interpretable representation of this input as a tensor</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>interpretable tensor</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>itp_tensor (Tensor)</p>
</dd>
</dl>
</dd></dl>
</dd></dl>
</section>
<section id="visualization">
<h2>Visualization<a class="headerlink" href="#visualization" title="Link to this heading">¶</a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="captum.attr.visualization.visualize_image_attr">
<span class="sig-prename descclassname"><span class="pre">captum.attr.visualization.</span></span><span class="sig-name descname"><span class="pre">visualize_image_attr</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">attr</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">original_image</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'heat_map'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sign</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'absolute_value'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">plt_fig_axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outlier_perc</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cmap</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha_overlay</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show_colorbar</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">title</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fig_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(6,</span> <span class="pre">6)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_pyplot</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#captum.attr.visualization.visualize_image_attr" title="Link to this definition">¶</a></dt>
<dd><p>Visualizes attribution for a given image by normalizing attribution values
of the desired sign (positive, negative, absolute value, or all) and displaying
them using the desired mode in a matplotlib figure.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>attr</strong> (<em>numpy.ndarray</em>) – Numpy array corresponding to attributions to be
visualized. Shape must be in the form (H, W, C), with
channels as last dimension. Shape must also match that of
the original image if provided.</p></li>
<li><p><strong>original_image</strong> (<em>numpy.ndarray</em><em>, </em><em>optional</em>) – Numpy array corresponding to
original image. Shape must be in the form (H, W, C), with
channels as the last dimension. Image can be provided either
with float values in range 0-1 or int values between 0-255.
This is a necessary argument for any visualization method
which utilizes the original image.
Default: None</p></li>
<li><p><strong>method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – <p>Chosen method for visualizing attribution.
Supported options are:</p>
<ol class="arabic simple">
<li><p><cite>heat_map</cite> - Display heat map of chosen attributions</p></li>
<li><p><cite>blended_heat_map</cite> - Overlay heat map over greyscale
version of original image. Parameter alpha_overlay
corresponds to alpha of heat map.</p></li>
<li><p><cite>original_image</cite> - Only display original image.</p></li>
<li><p><cite>masked_image</cite> - Mask image (pixel-wise multiply)
by normalized attribution values.</p></li>
<li><p><cite>alpha_scaling</cite> - Sets alpha channel of each pixel
to be equal to normalized attribution value.</p></li>
</ol>
<p>Default: <cite>heat_map</cite></p>
</p></li>
<li><p><strong>sign</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – <p>Chosen sign of attributions to visualize. Supported
options are:</p>
<ol class="arabic simple">
<li><p><cite>positive</cite> - Displays only positive pixel attributions.</p></li>
<li><p><cite>absolute_value</cite> - Displays absolute value of
attributions.</p></li>
<li><p><cite>negative</cite> - Displays only negative pixel attributions.</p></li>
<li><p><cite>all</cite> - Displays both positive and negative attribution
values. This is not supported for <cite>masked_image</cite> or
<cite>alpha_scaling</cite> modes, since signed information cannot
be represented in these modes.</p></li>
</ol>
<p>Default: <cite>absolute_value</cite></p>
</p></li>
<li><p><strong>plt_fig_axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a><em>, </em><em>optional</em>) – Tuple of matplotlib.pyplot.figure and axis
on which to visualize. If None is provided, then a new figure
and axis are created.
Default: None</p></li>
<li><p><strong>outlier_perc</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Top attribution values which
correspond to a total of outlier_perc percentage of the
total attribution are set to 1 and scaling is performed
using the minimum of these values. For sign=`all`, outliers
and scale value are computed using absolute value of
attributions.
Default: 2</p></li>
<li><p><strong>cmap</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – String corresponding to desired colormap for
heatmap visualization. This defaults to “Reds” for negative
sign, “Blues” for absolute value, “Greens” for positive sign,
and a spectrum from red to green for all. Note that this
argument is only used for visualizations displaying heatmaps.
Default: None</p></li>
<li><p><strong>alpha_overlay</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Alpha to set for heatmap when using
<cite>blended_heat_map</cite> visualization mode, which overlays the
heat map over the greyscaled original image.
Default: 0.5</p></li>
<li><p><strong>show_colorbar</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – Displays colorbar for heatmap below
the visualization. If given method does not use a heatmap,
then a colormap axis is created and hidden. This is
necessary for appropriate alignment when visualizing
multiple plots, some with colorbars and some without.
Default: False</p></li>
<li><p><strong>title</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – Title string for plot. If None, no title is
set.
Default: None</p></li>
<li><p><strong>fig_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a><em>, </em><em>optional</em>) – Size of figure created.
Default: (6,6)</p></li>
<li><p><strong>use_pyplot</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – If true, uses pyplot to create and show
figure and displays the figure after creating. If False,
uses Matplotlib object oriented API and simply returns a
figure object without showing.
Default: True.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><dl class="simple">
<dt><strong>figure</strong> (<em>matplotlib.pyplot.figure</em>):</dt><dd><p>Figure object on which visualization
is created. If plt_fig_axis argument is given, this is the
same figure provided.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>axis</strong> (<em>matplotlib.pyplot.axis</em>):</dt><dd><p>Axis object on which visualization
is created. If plt_fig_axis argument is given, this is the
same axis provided.</p>
</dd>
</dl>
</li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>2-element tuple of <strong>figure</strong>, <strong>axis</strong></p>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># ImageClassifier takes a single input tensor of images Nx3x32x32,</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># and returns an Nx10 tensor of class probabilities.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">ImageClassifier</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ig</span> <span class="o">=</span> <span class="n">IntegratedGradients</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Computes integrated gradients for class 3 for a given image .</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attribution</span><span class="p">,</span> <span class="n">delta</span> <span class="o">=</span> <span class="n">ig</span><span class="o">.</span><span class="n">attribute</span><span class="p">(</span><span class="n">orig_image</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Displays blended heat map visualization of computed attributions.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">_</span> <span class="o">=</span> <span class="n">visualize_image_attr</span><span class="p">(</span><span class="n">attribution</span><span class="p">,</span> <span class="n">orig_image</span><span class="p">,</span> <span class="s2">"blended_heat_map"</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="captum.attr.visualization.visualize_image_attr_multiple">
<span class="sig-prename descclassname"><span class="pre">captum.attr.visualization.</span></span><span class="sig-name descname"><span class="pre">visualize_image_attr_multiple</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">attr</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">original_image</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">methods</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">signs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">titles</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fig_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(8,</span> <span class="pre">6)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_pyplot</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#captum.attr.visualization.visualize_image_attr_multiple" title="Link to this definition">¶</a></dt>
<dd><p>Visualizes attribution using multiple visualization methods displayed
in a 1 x k grid, where k is the number of desired visualizations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>attr</strong> (<em>numpy.ndarray</em>) – Numpy array corresponding to attributions to be
visualized. Shape must be in the form (H, W, C), with
channels as last dimension. Shape must also match that of
the original image if provided.</p></li>
<li><p><strong>original_image</strong> (<em>numpy.ndarray</em><em>, </em><em>optional</em>) – Numpy array corresponding to
original image. Shape must be in the form (H, W, C), with
channels as the last dimension. Image can be provided either
with values in range 0-1 or 0-255. This is a necessary
argument for any visualization method which utilizes
the original image.</p></li>
<li><p><strong>methods</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>]</em>) – List of strings of length k, defining method
for each visualization. Each method must be a valid
string argument for method to visualize_image_attr.</p></li>
<li><p><strong>signs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>]</em>) – List of strings of length k, defining signs for
each visualization. Each sign must be a valid
string argument for sign to visualize_image_attr.</p></li>
<li><p><strong>titles</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>]</em><em>, </em><em>optional</em>) – List of strings of length k, providing
a title string for each plot. If None is provided, no titles
are added to subplots.
Default: None</p></li>
<li><p><strong>fig_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a><em>, </em><em>optional</em>) – Size of figure created.
Default: (8, 6)</p></li>
<li><p><strong>use_pyplot</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – If true, uses pyplot to create and show
figure and displays the figure after creating. If False,
uses Matplotlib object oriented API and simply returns a
figure object without showing.
Default: True.</p></li>
<li><p><strong>**kwargs</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><em>Any</em></a><em>, </em><em>optional</em>) – Any additional arguments which will be passed
to every individual visualization. Such arguments include
<cite>show_colorbar</cite>, <cite>alpha_overlay</cite>, <cite>cmap</cite>, etc.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><dl class="simple">
<dt><strong>figure</strong> (<em>matplotlib.pyplot.figure</em>):</dt><dd><p>Figure object on which visualization
is created. If plt_fig_axis argument is given, this is the
same figure provided.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>axis</strong> (<em>matplotlib.pyplot.axis</em>):</dt><dd><p>Axis object on which visualization
is created. If plt_fig_axis argument is given, this is the
same axis provided.</p>
</dd>
</dl>
</li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>2-element tuple of <strong>figure</strong>, <strong>axis</strong></p>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># ImageClassifier takes a single input tensor of images Nx3x32x32,</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># and returns an Nx10 tensor of class probabilities.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">ImageClassifier</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ig</span> <span class="o">=</span> <span class="n">IntegratedGradients</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Computes integrated gradients for class 3 for a given image .</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attribution</span><span class="p">,</span> <span class="n">delta</span> <span class="o">=</span> <span class="n">ig</span><span class="o">.</span><span class="n">attribute</span><span class="p">(</span><span class="n">orig_image</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Displays original image and heat map visualization of</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># computed attributions side by side.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">_</span> <span class="o">=</span> <span class="n">visualize_image_attr_multiple</span><span class="p">(</span><span class="n">attribution</span><span class="p">,</span> <span class="n">orig_image</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                    <span class="p">[</span><span class="s2">"original_image"</span><span class="p">,</span> <span class="s2">"heat_map"</span><span class="p">],</span> <span class="p">[</span><span class="s2">"all"</span><span class="p">,</span> <span class="s2">"positive"</span><span class="p">])</span>
</pre></div>
</div>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="captum.attr.visualization.visualize_timeseries_attr">
<span class="sig-prename descclassname"><span class="pre">captum.attr.visualization.</span></span><span class="sig-name descname"><span class="pre">visualize_timeseries_attr</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">attr</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x_values</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'overlay_individual'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sign</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'absolute_value'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">channel_labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">channels_last</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">plt_fig_axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outlier_perc</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cmap</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha_overlay</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.7</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show_colorbar</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">title</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fig_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(6,</span> <span class="pre">6)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_pyplot</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">pyplot_kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#captum.attr.visualization.visualize_timeseries_attr" title="Link to this definition">¶</a></dt>
<dd><p>Visualizes attribution for a given timeseries data by normalizing
attribution values of the desired sign (positive, negative, absolute value,
or all) and displaying them using the desired mode in a matplotlib figure.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>attr</strong> (<em>numpy.ndarray</em>) – Numpy array corresponding to attributions to be
visualized. Shape must be in the form (N, C) with channels
as last dimension, unless <cite>channels_last</cite> is set to True.
Shape must also match that of the timeseries data.</p></li>
<li><p><strong>data</strong> (<em>numpy.ndarray</em>) – Numpy array corresponding to the original,
equidistant timeseries data. Shape must be in the form
(N, C) with channels as last dimension, unless
<cite>channels_last</cite> is set to true.</p></li>
<li><p><strong>x_values</strong> (<em>numpy.ndarray</em><em>, </em><em>optional</em>) – Numpy array corresponding to the
points on the x-axis. Shape must be in the form (N, ). If
not provided, integers from 0 to N-1 are used.
Default: None</p></li>
<li><p><strong>method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – <p>Chosen method for visualizing attributions
overlaid onto data. Supported options are:</p>
<ol class="arabic simple">
<li><dl class="simple">
<dt><cite>overlay_individual</cite> - Plot each channel individually in</dt><dd><p>a separate panel, and overlay the attributions for each
channel as a heat map. The <cite>alpha_overlay</cite> parameter
controls the alpha of the heat map.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><cite>overlay_combined</cite> - Plot all channels in the same panel,</dt><dd><p>and overlay the average attributions as a heat map.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><cite>colored_graph</cite> - Plot each channel in a separate panel,</dt><dd><p>and color the graphs according to the attribution
values. Works best with color maps that does not contain
white or very bright colors.</p>
</dd>
</dl>
</li>
</ol>
<p>Default: <cite>overlay_individual</cite></p>
</p></li>
<li><p><strong>sign</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – <p>Chosen sign of attributions to visualize.
Supported options are:</p>
<ol class="arabic simple">
<li><p><cite>positive</cite> - Displays only positive pixel attributions.</p></li>
<li><dl class="simple">
<dt><cite>absolute_value</cite> - Displays absolute value of</dt><dd><p>attributions.</p>
</dd>
</dl>
</li>
<li><p><cite>negative</cite> - Displays only negative pixel attributions.</p></li>
<li><dl class="simple">
<dt><cite>all</cite> - Displays both positive and negative attribution</dt><dd><p>values.</p>
</dd>
</dl>
</li>
</ol>
<p>Default: <cite>absolute_value</cite></p>
</p></li>
<li><p><strong>channel_labels</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>]</em><em>, </em><em>optional</em>) – List of labels
corresponding to each channel in data.
Default: None</p></li>
<li><p><strong>channels_last</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – If True, data is expected to have
channels as the last dimension, i.e. (N, C). If False, data
is expected to have channels first, i.e. (C, N).
Default: True</p></li>
<li><p><strong>plt_fig_axis</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a><em>, </em><em>optional</em>) – Tuple of matplotlib.pyplot.figure and axis
on which to visualize. If None is provided, then a new figure
and axis are created.
Default: None</p></li>
<li><p><strong>outlier_perc</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Top attribution values which
correspond to a total of outlier_perc percentage of the
total attribution are set to 1 and scaling is performed
using the minimum of these values. For sign=`all`, outliers
and scale value are computed using absolute value of
attributions.
Default: 2</p></li>
<li><p><strong>cmap</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – String corresponding to desired colormap for
heatmap visualization. This defaults to “Reds” for negative
sign, “Blues” for absolute value, “Greens” for positive sign,
and a spectrum from red to green for all. Note that this
argument is only used for visualizations displaying heatmaps.
Default: None</p></li>
<li><p><strong>alpha_overlay</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Alpha to set for heatmap when using
<cite>blended_heat_map</cite> visualization mode, which overlays the
heat map over the greyscaled original image.
Default: 0.7</p></li>
<li><p><strong>show_colorbar</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a>) – Displays colorbar for heat map below
the visualization.</p></li>
<li><p><strong>title</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – Title string for plot. If None, no title is
set.
Default: None</p></li>
<li><p><strong>fig_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a><em>, </em><em>optional</em>) – Size of figure created.
Default: (6,6)</p></li>
<li><p><strong>use_pyplot</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a>) – If true, uses pyplot to create and show
figure and displays the figure after creating. If False,
uses Matplotlib object oriented API and simply returns a
figure object without showing.
Default: True.</p></li>
<li><p><strong>pyplot_kwargs</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Any</span></code></a></span>) – Keyword arguments forwarded to plt.plot, for example
<cite>linewidth=3</cite>, <cite>color=’black’</cite>, etc</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><dl class="simple">
<dt><strong>figure</strong> (<em>matplotlib.pyplot.figure</em>):</dt><dd><p>Figure object on which visualization
is created. If plt_fig_axis argument is given, this is the
same figure provided.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>axis</strong> (<em>matplotlib.pyplot.axis</em>):</dt><dd><p>Axis object on which visualization
is created. If plt_fig_axis argument is given, this is the
same axis provided.</p>
</dd>
</dl>
</li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>2-element tuple of <strong>figure</strong>, <strong>axis</strong></p>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Classifier takes input of shape (batch, length, channels)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">Classifier</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dl</span> <span class="o">=</span> <span class="n">DeepLift</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attribution</span> <span class="o">=</span> <span class="n">dl</span><span class="o">.</span><span class="n">attribute</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Pick the first sample and plot each channel in data in a separate</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># panel, with attributions overlaid</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">visualize_timeseries_attr</span><span class="p">(</span><span class="n">attribution</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s2">"overlay_individual"</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>
</section>
<section id="interpretable-embeddings">
<h2>Interpretable Embeddings<a class="headerlink" href="#interpretable-embeddings" title="Link to this heading">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="captum.attr.InterpretableEmbeddingBase">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">captum.attr.</span></span><span class="sig-name descname"><span class="pre">InterpretableEmbeddingBase</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">embedding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">full_name</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/captum/attr/_models/base.html#InterpretableEmbeddingBase"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#captum.attr.InterpretableEmbeddingBase" title="Link to this definition">¶</a></dt>
<dd><p>Since some embedding vectors, e.g. word are created and assigned in
the embedding layers of Pytorch models we need a way to access
those layers, generate the embeddings and subtract the baseline.
To do so, we separate embedding layers from the model, compute the
embeddings separately and do all operations needed outside of the model.
The original embedding layer is being replaced by
<cite>InterpretableEmbeddingBase</cite> layer which passes already
precomputed embedding vectors to the layers below.</p>
<p>Initialize internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="py method">
<dt class="sig sig-object py" id="captum.attr.InterpretableEmbeddingBase.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/captum/attr/_models/base.html#InterpretableEmbeddingBase.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#captum.attr.InterpretableEmbeddingBase.forward" title="Link to this definition">¶</a></dt>
<dd><p>The forward function of a wrapper embedding layer that takes and returns
embedding layer. It allows embeddings to be created outside of the model
and passes them seamlessly to the preceding layers of the model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>*inputs</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><em>Any</em></a><em>, </em><em>optional</em>) – A sequence of inputs arguments that the
forward function takes. Since forward functions can take any
type and number of arguments, this will ensure that we can
execute the forward pass using interpretable embedding layer.
Note that if inputs are specified, it is assumed that the first
argument is the embedding tensor generated using the
<cite>self.embedding</cite> layer using all input arguments provided in
<cite>inputs</cite> and <cite>kwargs</cite>.</p></li>
<li><p><strong>**kwargs</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><em>Any</em></a><em>, </em><em>optional</em>) – Similar to <cite>inputs</cite> we want to make sure
that our forward pass supports arbitrary number and type of
key-value arguments. If <cite>inputs</cite> is not provided, <cite>kwargs</cite> must
be provided and the first argument corresponds to the embedding
tensor generated using the <cite>self.embedding</cite>. Note that we make
here an assumption here that <cite>kwargs</cite> is an ordered dict which
is new in python 3.6 and is not guaranteed that it will
consistently remain that way in the newer versions. In case
current implementation doesn’t work for special use cases,
it is encouraged to override <cite>InterpretableEmbeddingBase</cite> and
address those specifics in descendant classes.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Returns a tensor which is the same as first argument passed
to the forward function.
It passes pre-computed embedding tensors to lower layers
without any modifications.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>embedding_tensor (Tensor)</p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="captum.attr.InterpretableEmbeddingBase.indices_to_embeddings">
<span class="sig-name descname"><span class="pre">indices_to_embeddings</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">input</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/captum/attr/_models/base.html#InterpretableEmbeddingBase.indices_to_embeddings"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#captum.attr.InterpretableEmbeddingBase.indices_to_embeddings" title="Link to this definition">¶</a></dt>
<dd><p>Maps indices to corresponding embedding vectors. E.g. word embeddings</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>*input</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><em>Any</em></a><em>, </em><em>optional</em>) – This can be a tensor(s) of input indices or any
other variable necessary to comput the embeddings. A typical
example of input indices are word or token indices.</p></li>
<li><p><strong>**kwargs</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.13)"><em>Any</em></a><em>, </em><em>optional</em>) – Similar to <cite>input</cite> this can be any sequence
of key-value arguments necessary to compute final embedding
tensor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A tensor of word embeddings corresponding to the
indices specified in the input</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tensor</p>
</dd>
</dl>
</dd></dl>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="captum.attr.configure_interpretable_embedding_layer">
<span class="sig-prename descclassname"><span class="pre">captum.attr.</span></span><span class="sig-name descname"><span class="pre">configure_interpretable_embedding_layer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embedding_layer_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'embedding'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/captum/attr/_models/base.html#configure_interpretable_embedding_layer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#captum.attr.configure_interpretable_embedding_layer" title="Link to this definition">¶</a></dt>
<dd><p>This method wraps a model’s embedding layer with an interpretable embedding
layer that allows us to access the embeddings through their indices.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.5)"><em>torch.nn.Module</em></a>) – An instance of PyTorch model that contains embeddings.</p></li>
<li><p><strong>embedding_layer_name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – The name of the embedding layer
in the <cite>model</cite> that we would like to make interpretable.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>An instance of</dt><dd><p><cite>InterpretableEmbeddingBase</cite> embedding layer that wraps model’s
embedding layer that is being accessed through
<cite>embedding_layer_name</cite>.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>interpretable_emb (<a class="reference internal" href="#captum.attr.InterpretableEmbeddingBase" title="captum.attr.InterpretableEmbeddingBase">InterpretableEmbeddingBase</a>)</p>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Let's assume that we have a DocumentClassifier model that</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># has a word embedding layer named 'embedding'.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># To make that layer interpretable we need to execute the</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># following command:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">DocumentClassifier</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">interpretable_emb</span> <span class="o">=</span> <span class="n">configure_interpretable_embedding_layer</span><span class="p">(</span><span class="n">net</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>   <span class="s1">'embedding'</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># then we can use interpretable embedding to convert our</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># word indices into embeddings.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Let's assume that we have the following word indices</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># we can access word embeddings for those indices with the command</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># line stated below.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_emb</span> <span class="o">=</span> <span class="n">interpretable_emb</span><span class="o">.</span><span class="n">indices_to_embeddings</span><span class="p">(</span><span class="n">input_indices</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Let's assume that we want to apply integrated gradients to</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># our model and that target attribution class is 3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ig</span> <span class="o">=</span> <span class="n">IntegratedGradients</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attribution</span> <span class="o">=</span> <span class="n">ig</span><span class="o">.</span><span class="n">attribute</span><span class="p">(</span><span class="n">input_emb</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># after we finish the interpretation we need to remove</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># interpretable embedding layer with the following command:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">remove_interpretable_embedding_layer</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">interpretable_emb</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>
<dl class="py function">
<dt class="sig sig-object py" id="captum.attr.remove_interpretable_embedding_layer">
<span class="sig-prename descclassname"><span class="pre">captum.attr.</span></span><span class="sig-name descname"><span class="pre">remove_interpretable_embedding_layer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">interpretable_emb</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/captum/attr/_models/base.html#remove_interpretable_embedding_layer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#captum.attr.remove_interpretable_embedding_layer" title="Link to this definition">¶</a></dt>
<dd><p>Removes interpretable embedding layer and sets back original
embedding layer in the model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.5)"><em>torch.nn.Module</em></a>) – An instance of PyTorch model that contains embeddings</p></li>
<li><p><strong>interpretable_emb</strong> (<a class="reference internal" href="#captum.attr.InterpretableEmbeddingBase" title="captum.attr.InterpretableEmbeddingBase"><em>InterpretableEmbeddingBase</em></a>) – An instance of
<cite>InterpretableEmbeddingBase</cite> that was originally created in
<cite>configure_interpretable_embedding_layer</cite> function and has
to be removed after interpretation is finished.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a></span></p>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Let's assume that we have a DocumentClassifier model that</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># has a word embedding layer named 'embedding'.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># To make that layer interpretable we need to execute the</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># following command:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">DocumentClassifier</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">interpretable_emb</span> <span class="o">=</span> <span class="n">configure_interpretable_embedding_layer</span><span class="p">(</span><span class="n">net</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>   <span class="s1">'embedding'</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># then we can use interpretable embedding to convert our</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># word indices into embeddings.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Let's assume that we have the following word indices</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># we can access word embeddings for those indices with the command</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># line stated below.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_emb</span> <span class="o">=</span> <span class="n">interpretable_emb</span><span class="o">.</span><span class="n">indices_to_embeddings</span><span class="p">(</span><span class="n">input_indices</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Let's assume that we want to apply integrated gradients to</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># our model and that target attribution class is 3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ig</span> <span class="o">=</span> <span class="n">IntegratedGradients</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attribution</span> <span class="o">=</span> <span class="n">ig</span><span class="o">.</span><span class="n">attribute</span><span class="p">(</span><span class="n">input_emb</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># after we finish the interpretation we need to remove</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># interpretable embedding layer with the following command:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">remove_interpretable_embedding_layer</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">interpretable_emb</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>
</section>
<section id="token-reference-base">
<h2>Token Reference Base<a class="headerlink" href="#token-reference-base" title="Link to this heading">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="captum.attr.TokenReferenceBase">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">captum.attr.</span></span><span class="sig-name descname"><span class="pre">TokenReferenceBase</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">reference_token_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/captum/attr/_models/base.html#TokenReferenceBase"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#captum.attr.TokenReferenceBase" title="Link to this definition">¶</a></dt>
<dd><p>A base class for creating reference (aka baseline) tensor for a sequence of
tokens. A typical example of such token is <cite>PAD</cite>. Users need to provide the
index of the reference token in the vocabulary as an argument to
<cite>TokenReferenceBase</cite> class.</p>
<dl class="py method">
<dt class="sig sig-object py" id="captum.attr.TokenReferenceBase.generate_reference">
<span class="sig-name descname"><span class="pre">generate_reference</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sequence_length</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/captum/attr/_models/base.html#TokenReferenceBase.generate_reference"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#captum.attr.TokenReferenceBase.generate_reference" title="Link to this definition">¶</a></dt>
<dd><p>Generated reference tensor of given <cite>sequence_length</cite> using
<cite>reference_token_idx</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sequence_length</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – The length of the reference sequence</p></li>
<li><p><strong>device</strong> (<a class="reference external" href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.device" title="(in PyTorch v2.5)"><em>torch.device</em></a>) – The device on which the reference tensor will
be created.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>A sequence of reference token with shape:</dt><dd><p>[sequence_length]</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tensor</p>
</dd>
</dl>
</dd></dl>
</dd></dl>
</section>
<section id="linear-models">
<h2>Linear Models<a class="headerlink" href="#linear-models" title="Link to this heading">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="captum._utils.models.model.Model">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">captum._utils.models.model.</span></span><span class="sig-name descname"><span class="pre">Model</span></span><a class="reference internal" href="_modules/captum/_utils/models/model.html#Model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#captum._utils.models.model.Model" title="Link to this definition">¶</a></dt>
<dd><p>Abstract Class to describe the interface of a trainable model to be used
within the algorithms of captum.</p>
<p>Please note that this is an experimental feature.</p>
<dl class="py method">
<dt class="sig sig-object py" id="captum._utils.models.model.Model.fit">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_data</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/captum/_utils/models/model.html#Model.fit"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#captum._utils.models.model.Model.fit" title="Link to this definition">¶</a></dt>
<dd><p>Override this method to actually train your model.</p>
<p>The specification of the dataloader will be supplied by the algorithm
you are using within captum. This will likely be a supervised learning
task, thus you should expect batched (x, y) pairs or (x, y, w) triples.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>train_data</strong> (<em>DataLoader</em>) – The data to train on</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Dict</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.13)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>, <a class="reference external" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.5)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>]]]</span></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Optional statistics about training, e.g.  iterations it took to
train, training loss, etc.</p>
</dd>
</dl>
</dd></dl>
<dl class="py method">
<dt class="sig sig-object py" id="captum._utils.models.model.Model.representation">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">representation</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/captum/_utils/models/model.html#Model.representation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#captum._utils.models.model.Model.representation" title="Link to this definition">¶</a></dt>
<dd><p>Returns the underlying representation of the interpretable model. For a
linear model this is simply a tensor (the concatenation of weights
and bias). For something slightly more complicated, such as a decision
tree, this could be the nodes of a decision tree.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.5)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span></p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A Tensor describing the representation of the model.</p>
</dd>
</dl>
</dd></dl>
</dd></dl>
<dl class="py class">
<dt class="sig sig-object py" id="captum._utils.models.linear_model.SkLearnLinearModel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">captum._utils.models.linear_model.</span></span><span class="sig-name descname"><span class="pre">SkLearnLinearModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sklearn_module</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/captum/_utils/models/linear_model/model.html#SkLearnLinearModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#captum._utils.models.linear_model.SkLearnLinearModel" title="Link to this definition">¶</a></dt>
<dd><p>Factory class to construct a <cite>LinearModel</cite> with sklearn training method.</p>
<p>Please note that this assumes:</p>
<ol class="arabic simple" start="0">
<li><p>You have sklearn and numpy installed</p></li>
<li><p>The dataset can fit into memory</p></li>
</ol>
<p>SkLearn support does introduce some slight overhead as we convert the
tensors to numpy and then convert the resulting trained model to a
<cite>LinearModel</cite> object. However, this conversion should be negligible.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sklearn_module</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a></span>) – <p>The module under sklearn to construct and use for training, e.g.
use “svm.LinearSVC” for an SVM or “linear_model.Lasso” for Lasso.</p>
<p>There are factory classes defined for you for common use cases,
such as <cite>SkLearnLasso</cite>.</p>
</p></li>
<li><p><strong>kwargs</strong> – The kwargs to pass to the construction of the sklearn model</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="captum._utils.models.linear_model.SkLearnLinearModel.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_data</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/captum/_utils/models/linear_model/model.html#SkLearnLinearModel.fit"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#captum._utils.models.linear_model.SkLearnLinearModel.fit" title="Link to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_data</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader" title="(in PyTorch v2.5)"><code class="xref py py-class docutils literal notranslate"><span class="pre">DataLoader</span></code></a></span>) – Train data to use</p></li>
<li><p><strong>kwargs</strong> – Arguments to feed to <cite>.fit</cite> method for sklearn</p></li>
</ul>
</dd>
</dl>
</dd></dl>
</dd></dl>
<dl class="py class">
<dt class="sig sig-object py" id="captum._utils.models.linear_model.SkLearnLinearRegression">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">captum._utils.models.linear_model.</span></span><span class="sig-name descname"><span class="pre">SkLearnLinearRegression</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/captum/_utils/models/linear_model/model.html#SkLearnLinearRegression"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#captum._utils.models.linear_model.SkLearnLinearRegression" title="Link to this definition">¶</a></dt>
<dd><p>Factory class. Trains a model with <cite>sklearn.linear_model.LinearRegression</cite>.</p>
<p>Any arguments provided to the sklearn constructor can be provided
as kwargs here.</p>
<dl class="py method">
<dt class="sig sig-object py" id="captum._utils.models.linear_model.SkLearnLinearRegression.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_data</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/captum/_utils/models/linear_model/model.html#SkLearnLinearRegression.fit"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#captum._utils.models.linear_model.SkLearnLinearRegression.fit" title="Link to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_data</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader" title="(in PyTorch v2.5)"><code class="xref py py-class docutils literal notranslate"><span class="pre">DataLoader</span></code></a></span>) – Train data to use</p></li>
<li><p><strong>kwargs</strong> – Arguments to feed to <cite>.fit</cite> method for sklearn</p></li>
</ul>
</dd>
</dl>
</dd></dl>
</dd></dl>
<dl class="py class">
<dt class="sig sig-object py" id="captum._utils.models.linear_model.SkLearnLasso">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">captum._utils.models.linear_model.</span></span><span class="sig-name descname"><span class="pre">SkLearnLasso</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/captum/_utils/models/linear_model/model.html#SkLearnLasso"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#captum._utils.models.linear_model.SkLearnLasso" title="Link to this definition">¶</a></dt>
<dd><p>Factory class. Trains a <cite>LinearModel</cite> model with
<cite>sklearn.linear_model.Lasso</cite>. You will need sklearn version &gt;= 0.23 to
support sample weights.</p>
<dl class="py method">
<dt class="sig sig-object py" id="captum._utils.models.linear_model.SkLearnLasso.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_data</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/captum/_utils/models/linear_model/model.html#SkLearnLasso.fit"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#captum._utils.models.linear_model.SkLearnLasso.fit" title="Link to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_data</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader" title="(in PyTorch v2.5)"><code class="xref py py-class docutils literal notranslate"><span class="pre">DataLoader</span></code></a></span>) – Train data to use</p></li>
<li><p><strong>kwargs</strong> – Arguments to feed to <cite>.fit</cite> method for sklearn</p></li>
</ul>
</dd>
</dl>
</dd></dl>
</dd></dl>
<dl class="py class">
<dt class="sig sig-object py" id="captum._utils.models.linear_model.SkLearnRidge">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">captum._utils.models.linear_model.</span></span><span class="sig-name descname"><span class="pre">SkLearnRidge</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/captum/_utils/models/linear_model/model.html#SkLearnRidge"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#captum._utils.models.linear_model.SkLearnRidge" title="Link to this definition">¶</a></dt>
<dd><p>Factory class. Trains a model with <cite>sklearn.linear_model.Ridge</cite>.</p>
<p>Any arguments provided to the sklearn constructor can be provided
as kwargs here.</p>
<dl class="py method">
<dt class="sig sig-object py" id="captum._utils.models.linear_model.SkLearnRidge.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_data</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/captum/_utils/models/linear_model/model.html#SkLearnRidge.fit"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#captum._utils.models.linear_model.SkLearnRidge.fit" title="Link to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_data</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader" title="(in PyTorch v2.5)"><code class="xref py py-class docutils literal notranslate"><span class="pre">DataLoader</span></code></a></span>) – Train data to use</p></li>
<li><p><strong>kwargs</strong> – Arguments to feed to <cite>.fit</cite> method for sklearn</p></li>
</ul>
</dd>
</dl>
</dd></dl>
</dd></dl>
<dl class="py class">
<dt class="sig sig-object py" id="captum._utils.models.linear_model.SGDLinearModel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">captum._utils.models.linear_model.</span></span><span class="sig-name descname"><span class="pre">SGDLinearModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/captum/_utils/models/linear_model/model.html#SGDLinearModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#captum._utils.models.linear_model.SGDLinearModel" title="Link to this definition">¶</a></dt>
<dd><p>Factory class. Construct a a <cite>LinearModel</cite> with the
<cite>sgd_train_linear_model</cite> as the train method</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>kwargs</strong> – Arguments send to <cite>self._construct_model_params</cite> after
<cite>self.fit</cite> is called. Please refer to that method for parameter
documentation.</p>
</dd>
</dl>
</dd></dl>
<dl class="py class">
<dt class="sig sig-object py" id="captum._utils.models.linear_model.SGDLasso">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">captum._utils.models.linear_model.</span></span><span class="sig-name descname"><span class="pre">SGDLasso</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/captum/_utils/models/linear_model/model.html#SGDLasso"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#captum._utils.models.linear_model.SGDLasso" title="Link to this definition">¶</a></dt>
<dd><p>Factory class to train a <cite>LinearModel</cite> with SGD
(<cite>sgd_train_linear_model</cite>) whilst setting appropriate parameters to
optimize for ridge regression loss. This optimizes L2 loss + alpha * L1
regularization.</p>
<p>Please note that with SGD it is not guaranteed that weights will
converge to 0.</p>
<dl class="py method">
<dt class="sig sig-object py" id="captum._utils.models.linear_model.SGDLasso.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_data</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/captum/_utils/models/linear_model/model.html#SGDLasso.fit"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#captum._utils.models.linear_model.SGDLasso.fit" title="Link to this definition">¶</a></dt>
<dd><p>Calls <cite>self.train_fn</cite></p>
</dd></dl>
</dd></dl>
<dl class="py class">
<dt class="sig sig-object py" id="captum._utils.models.linear_model.SGDRidge">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">captum._utils.models.linear_model.</span></span><span class="sig-name descname"><span class="pre">SGDRidge</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/captum/_utils/models/linear_model/model.html#SGDRidge"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#captum._utils.models.linear_model.SGDRidge" title="Link to this definition">¶</a></dt>
<dd><p>Factory class to train a <cite>LinearModel</cite> with SGD
(<cite>sgd_train_linear_model</cite>) whilst setting appropriate parameters to
optimize for ridge regression loss. This optimizes L2 loss + alpha *
L2 regularization.</p>
<dl class="py method">
<dt class="sig sig-object py" id="captum._utils.models.linear_model.SGDRidge.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_data</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/captum/_utils/models/linear_model/model.html#SGDRidge.fit"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#captum._utils.models.linear_model.SGDRidge.fit" title="Link to this definition">¶</a></dt>
<dd><p>Calls <cite>self.train_fn</cite></p>
</dd></dl>
</dd></dl>
</section>
<section id="baselines">
<h2>Baselines<a class="headerlink" href="#baselines" title="Link to this heading">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="captum.attr.ProductBaselines">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">captum.attr.</span></span><span class="sig-name descname"><span class="pre">ProductBaselines</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">baseline_values</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/captum/attr/_utils/baselines.html#ProductBaselines"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#captum.attr.ProductBaselines" title="Link to this definition">¶</a></dt>
<dd><p>A Callable Baselines class that returns a sample from the Cartesian product of
the inputs’ available baselines.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>baseline_values</strong> (<em>List</em><em> or </em><em>Dict</em>) – A list or dict of lists containing
the possible values for each feature. If a dict is provided, the keys
can a string of the feature name and the values is a list of available
baselines. The keys can also be a tuple of strings to group
multiple features whose baselines are not independent to each other.
If the key is a tuple, the value must be a list of tuples of
the corresponding values.</p>
</dd>
</dl>
</dd></dl>
</section>
</section>
</div>
</div>
</div>
<div aria-label="Main" class="sphinxsidebar" role="navigation">
<div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="index.html">Captum</a></h1>
<search id="searchbox" role="search" style="display: none">
<div class="searchformwrapper">
<form action="search.html" class="search" method="get">
<input aria-labelledby="searchlabel" autocapitalize="off" autocomplete="off" autocorrect="off" name="q" placeholder="Search" spellcheck="false" type="text"/>
<input type="submit" value="Go"/>
</form>
</div>
</search>
<script>document.getElementById('searchbox').style.display = "block"</script><h3>Navigation</h3>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="attribution.html">Attribution</a></li>
<li class="toctree-l1"><a class="reference internal" href="llm_attr.html">LLM Attribution Classes</a></li>
<li class="toctree-l1"><a class="reference internal" href="noise_tunnel.html">NoiseTunnel</a></li>
<li class="toctree-l1"><a class="reference internal" href="layer.html">Layer Attribution</a></li>
<li class="toctree-l1"><a class="reference internal" href="neuron.html">Neuron Attribution</a></li>
<li class="toctree-l1"><a class="reference internal" href="metrics.html">Metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="robust.html">Robustness</a></li>
<li class="toctree-l1"><a class="reference internal" href="concept.html">Concept-based Interpretability</a></li>
<li class="toctree-l1"><a class="reference internal" href="influence.html">Influential Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="module.html">Module</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Utilities</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#interpretable-input">Interpretable Input</a></li>
<li class="toctree-l2"><a class="reference internal" href="#visualization">Visualization</a></li>
<li class="toctree-l2"><a class="reference internal" href="#interpretable-embeddings">Interpretable Embeddings</a></li>
<li class="toctree-l2"><a class="reference internal" href="#token-reference-base">Token Reference Base</a></li>
<li class="toctree-l2"><a class="reference internal" href="#linear-models">Linear Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="#baselines">Baselines</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="base_classes.html">Base Classes</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Insights API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="insights.html">Insights</a></li>
<li class="toctree-l1"><a class="reference internal" href="insights.html#features">Features</a></li>
</ul>
<div class="relations">
<h3>Related Topics</h3>
<ul>
<li><a href="index.html">Documentation overview</a><ul>
<li>Previous: <a href="gaussian_stg.html" title="previous chapter">GaussianStochasticGates</a></li>
<li>Next: <a href="base_classes.html" title="next chapter">Base Classes</a></li>
</ul></li>
</ul>
</div>
</div>
</div>
<div class="clearer"></div>
</div></div></div><footer class="nav-footer" id="footer"><section class="sitemap"><div class="footerSection"><h5>Docs</h5><a href="/docs/introduction">Introduction</a><a href="/docs/getting_started">Getting Started</a><a href="/tutorials/">Tutorials</a><a href="/api/">API Reference</a></div><div class="footerSection"><h5>Legal</h5><a href="https://opensource.facebook.com/legal/privacy/" target="_blank" rel="noreferrer noopener">Privacy</a><a href="https://opensource.facebook.com/legal/terms/" target="_blank" rel="noreferrer noopener">Terms</a></div><div class="footerSection"><h5>Social</h5><div class="social"><a class="github-button" href="https://github.com/pytorch/captum" data-count-href="https://github.com/pytorch/captum/stargazers" data-show-count="true" data-count-aria-label="# stargazers on GitHub" aria-label="Star Captum on GitHub">captum</a></div></div></section><a href="https://opensource.facebook.com/" target="_blank" rel="noreferrer noopener" class="fbOpenSource"><img src="/img/oss_logo.png" alt="Facebook Open Source" width="170" height="45"/></a><section class="copyright"> Copyright © 2024 Facebook Inc.</section><script>
            (function() {
              var BAD_BASE = '/captum/';
              if (window.location.origin !== 'https://captum.ai') {
                var pathname = window.location.pathname;
                var newPathname = pathname.slice(pathname.indexOf(BAD_BASE) === 0 ? BAD_BASE.length : 1);
                var newLocation = 'https://captum.ai/' + newPathname;
                console.log('redirecting to ' + newLocation);
                window.location.href = newLocation;
              }
            })();
          </script></footer></div><script type="text/javascript" src="https://cdn.jsdelivr.net/docsearch.js/1/docsearch.min.js"></script><script>
                document.addEventListener('keyup', function(e) {
                  if (e.target !== document.body) {
                    return;
                  }
                  // keyCode for '/' (slash)
                  if (e.keyCode === 191) {
                    const search = document.getElementById('search_input_react');
                    search && search.focus();
                  }
                });
              </script><script>
              var search = docsearch({
                
                apiKey: '207c27d819f967749142d8611de7cb19',
                indexName: 'captum',
                inputSelector: '#search_input_react'
              });
            </script></body></html>